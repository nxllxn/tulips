<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>并发编程 on Tulips</title>
    <link>https://www.tlst.cc/categories/%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B/</link>
    <description>Recent content in 并发编程 on Tulips</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>zh-cn</language>
    <copyright>Copyright @ 2022 郁金香啊</copyright>
    <lastBuildDate>Wed, 30 Mar 2022 12:44:33 +0800</lastBuildDate><atom:link href="https://www.tlst.cc/categories/%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Java内存模型</title>
      <link>https://www.tlst.cc/post/java-concurrent-programming-02/</link>
      <pubDate>Wed, 30 Mar 2022 12:44:33 +0800</pubDate>
      
      <guid>https://www.tlst.cc/post/java-concurrent-programming-02/</guid>
      <description>在我们学习操作系统时，有一个章节会讲数据存储相关的的内容，那个经典的金字塔模型。哈哈，又一个Trade off 的完美诠释。这个金字塔模型中指出，通常我们可以很容易的获得一些存储设备，其数据容量大，成本低廉，但是访问速度较慢，比如我们常见的磁盘，甚至可以扩展到网盘。我们还有一些存储介质，其容量非常小，小到当我们使用这类存储介质所能提供的空间时，不得不小心翼翼，而且此类介质一般价格十分高昂，但是由于这类存储介质相对来说更加靠近我们的计算单元，所以其访问速度非常非常快，几乎可以忽略不记，比如我们的寄存器。
在我们讨论这个抽象的金字塔概念之前，让我们先看一个生活中比较常见的例子。比如你是一个木匠，你准备做点科研，造个什么木制品出来，这个作品相当精妙，以至于需要十几种甚至更多的工具来帮助你完成，假定这些工具目前放在你的车库。
现实中，当你用工具的时候你并不会总是去车库找工具，你可能会先找一个小盒子将你认为在不远的将来你可能会用到的工具先一次性取出来。此外你甚至不会说是每次用什么工具都会去盒子里面找一下，一般你总会保证伸手就够得着的地方有最近需要使用的那么几件工具，此外，你的手上可能握着正在使用的一到两件工具。你会发现，从车库到盒子到手够得着的位置再到你的手上，能够维护的工具数量越来越少，车库总是能够放上很多的工具，箱子里面可能有十几个，在身边就能够着的区域可能就只能放四五个了，手上可能拿两个工具已经是极限了。
但是不可否认，这的确会对你的工作效率产生很大的提升，其实这得益于两个定理，第一个，现在被使用的工具在不远的未来更可能会被用到，和这个很好理解，同一个工具你可能会用很长一段时间；一个工具被用到，与它相对来说比较接近，比如功能相似的一些工具在不远的将来更有可能被用到，比如各种型号的木头抛光器。
当然了，有时候你会把手上的工具换下来，然后可能会发现工具没在旁边，你可能还是会去翻盒子，如果盒子里面找不到，比如你压根儿就忘了从车库里取出来，你那么你就不得不跑到车库里面再取一遍了。而且如果还有其他人也依赖于这个车库来获取工具的话，你可能还得及时的将工具还回去，如果每次用完就还回去，你可能会在车库和工作室之间跑来跑去，很影响工作效率；但是如果每次都是到最后作品完成再还回去，可能其他人要抱怨了。聪明的你应该又看到另一个** Trade off**的影子了吧，哈哈。
让我们再回到之前的金字塔底部，我们现在好像瞥见到了两个极端，一个是金字塔的底部，另一个则是金字塔的顶端。便宜，大容量但是速度慢；速度足够快但是价格高昂且容量很小。好在金字塔不止有底部和顶端，它还有中间的部分，这也是我们的Trade off策略得以游走的空间。我们从金字塔的最底部慢慢向上攀爬探索：
   越过磁盘，首先我们可能接触的内存，虽然断电后数据就会丢失，但是其访问速度相较于磁盘已经有了质的提升，当然了，相对于磁盘，其价格更高，容量也要小很多，在1TB的固态硬盘充斥在人们的生活中时，我们通常可以操作的内存空间一般只有8G，16G等；很多的操作系统也通过虚拟内存突破了物理内存的限制，所以一般16G的内存对于绝大多数人来说都已经足够了。
   我们继续向上攀爬，此时我们会遇到称为高速缓存的东西，一般有两级，我们称之为二级缓存和以一级缓存，实际上我们的CPU尝试加载数据时，并不会直接和我们的内存打交道，我们首先会将需要访问的内存连同周边临近的内存区域先加载到二级缓存中，然后再加载一部分到一级缓存中。现在当CPU尝试去加载数据的时候，花在IO上的时间就很短了。
   然后就是寄存器了，如果你写过汇编或者有看过反编译后的Java的字节码指令，你可能会看到，我们是如何精细地一个一个存储单元的进行访问和管理的。空间很小，但是因为他们是最接近CPU的位置，它们的存在让我们的指令序列得以流畅的执行，而不必每次都花费大量时间等待IO。
Java作为一门编程语言以及一个平台，其底层实现的时候，其实也逃不掉这些模式的束缚。只不过我们上面讨论的是硬件资源上的一些Trade off，Java内存模型是在这个基础之上又进行了一层抽象，但是其内在原理还是相通的。
本系列文章在编写时大量参考了《Java并发编程艺术》一书，原书将Java内存模型放在第三章，将Java语言中的一些特性以及实现原理，比如synchronized，volatile等关键字放在第二章。当我在准备第二篇文章的时候，老师感觉写起来不是很顺畅，因为里面有很多的概念其实是依赖于Java内存模型中的很多内容的。所以就调整了一下顺序，将JMM提到前面来写一下。
目录 Java内存模型 在并发编程中，我们有两个问题需要解决，当多个线程共同合作完成一个或者多个特定问题时，我们定义好线程之间如何进行通信以及如何进行同步的。通信是指线程之间如何交换信息，包括获取处理的入参输出处理的结果等等。线程之前通信的方式两种，消息传递和共享内存。
其中消息传递这种模式，在一些移动开发时可能会遇到，比如Android开发时，我们会有一个UI线程，还会有一些子线程，子线程一般用于去获取数据，比如调用一个接口获取数据，而主线程我们也叫UI线程的话，顾名思义，主要工作是进行UI的渲染。我们不希望在UI线程里面去进行IO操作，这样可能会导致线程阻塞相当长的时间，界面就无法进行组件的渲染，更无法响应用户的操作，这对用户来说是完全不可接受的。真因为这样我们才会在子线程中做IO相关的操作。当子线程成功加载好数据之后，我们会使用一种消息传递的机制来通知UI线程，我已经成功获取了数据，你可以拿最新的数据进行渲染了。
相比于消息传递，共享内存这种方式来进行数据共享就相对来说要常见的多了。多个线程往往通过读写内存中的公共状态来进行隐式通信。
不管是消息传递还是共享内存，我们都需要做一件事情，那就是指定一个数据的同步访问机制，避免由于大家同时对数据进行读写导致最终获得一个错误的结果。在消息传递模型中，消息的接收一定在消息的发送之后，因此共享数据的访问一直都是串行的，同步是隐式进行的。在共享内存模型中，数据访问的顺序无法预见，所以程序员必须显式的指定某个方法或者某个代码片段需要在线程之间互斥的执行，同步是显式进行的。
Java并发采用的是共享内存模型，默认情况下，Java线程之前的通信总是隐式进行的，整个通信过程对程序员完全透明，如果程序员没有意识到这个并且不手动加以控制就不可能得到正确的结果。
Java内存模型的抽象结构 Java定义了一套抽象的模型来控制线程间在进行内存共享时共享内容在各个线程之间的可见性，这个模型决定了一个线程对一个共享变量的写入何时对另一个线程可见。
从抽象角度来看，JMM定义了主存和线程工作内存之间的关系。线程间的共享变量存储在主存中，而每一个线程都有一个线程私有的本地内存，我们也称之为工作内存，工作内存中存储了该线程读写共享变量的副本。
工作内存是JMM的一个抽象概念，并不是真实存在的，它涵盖了寄存器，高速缓存，写缓冲区以及其他硬件以及编译器优化。
 假定两个线程A，B同时访问一个共享变量var，根据JMM，除了主存中的数据var，线程A，B在工作内存中还存在两个副本，var-A，var-B。当线程A，B对共享变量进行读取或者修改时，他们直接操作工作内存中的副本。
那么当其中一个线程对数据进行了更新时，如果另一个线程想要读取到最新的结果，我们就必须将更新过后的值刷新到主内存中去，然后另一个线程在读取数据时，不能直接从工作内存的副本中读取过期的数据，其必须直接从主存中加载最新的结果。而JMM正是通过控制朱迅与每个线程的本地内存之间的交互，来为Java程序员提供内存可见性的保证。
指令重排序 在执行程序时，为了提高性能，编译器和处理器常常会对指令做重排序，其分为以下三种类型：
 编译器优化的指令重排序 - 编译器在不改变单线程语义的情况下，可以重新安排语句的执行顺序 指令级并行重排序 - 如果多条指令之间不存在数据依赖性，处理器可以改变语句对应机器指令的执行顺序。 内存系统的重排序 - 由于处理器使用缓存和读写缓冲区，使得加载和存储操作看上去可能在乱序执行。  重排序能够提升性能，但是也可能带来一些内存可见性问题，比如在单例模式实现的例子中就会讲到，指令重排序是如何导致可见性问题并使用volatile关键字来解决它的。</description>
    </item>
    
    <item>
      <title>Java并发机制的底层实现原理</title>
      <link>https://www.tlst.cc/post/java-concurrent-programming-03/</link>
      <pubDate>Wed, 30 Mar 2022 12:44:33 +0800</pubDate>
      
      <guid>https://www.tlst.cc/post/java-concurrent-programming-03/</guid>
      <description>无规矩不成方圆，为了获得并发编程带来的好处，我们需要定义一套严谨的控制机制。只有在这套机制的控制下，JVM才能够按照预期执行我们的字节码，只有了解这套机制，我们才能够编写出正确的代码得到正确的结果。
目录 Java并发机制的底层实现原理 Java为了方便编程人员进行实现，其暴露了很多的关键字以及Api，比如synchronized，volatile以及各种Lock。我们很容易使用这些关键字以及Api实现出一些线程安全的代码，但是我们不能止步于此，要知道在软件开发的世界里，你可以在各种各样的地方找到一些Trade off的完美诠释，同样在并发编程时，相对简单的一个实现方式通常意味着你可能牺牲了一些性能，换句话说，再花同样的时间你可能能够做的更好，在保证线程安全的情况下还能够让你的程序仍然高效的执行。。所以让我们一起看下这些特性如何使用以及其背后的原理吧。
第一个关键字 - volatile volatile，这个单词直接翻译过来是易挥发的，比如酒精，汽油等物质的挥发性。在计算机相关的属于里面，或者说是在Java语言里面，通常我们会将其翻译成易失的。我猜之所以使用这个单词是因为所有被volatile关键字标注的变量其引用的内存区域需要保证一种可见性，而JVM通过一种机制总是将最新的内容写到主存中并且也总是从主存中读取数据来实现这个，所以对于工作内存中的值，其总是很容易miss，所以才有了这么一个定义。
这一段话里面可能涉及了很多的概念，其中非常重要的有Java内存模型相关的内容，其会在后面的文章中被覆盖到，如果暂时不清楚的话可以先跳到内存模型相关的文章中了解对应的内容。
待补充</description>
    </item>
    
  </channel>
</rss>
