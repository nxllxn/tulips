





















































































































































































































































[{"categories":["Java","并发编程"],"contents":"在我们学习操作系统时，有一个章节会讲数据存储相关的的内容，那个经典的金字塔模型。哈哈，又一个Trade off 的完美诠释。这个金字塔模型中指出，通常我们可以很容易的获得一些存储设备，其数据容量大，成本低廉，但是访问速度较慢，比如我们常见的磁盘，甚至可以扩展到网盘。我们还有一些存储介质，其容量非常小，小到当我们使用这类存储介质所能提供的空间时，不得不小心翼翼，而且此类介质一般价格十分高昂，但是由于这类存储介质相对来说更加靠近我们的计算单元，所以其访问速度非常非常快，几乎可以忽略不记，比如我们的寄存器。\n在我们讨论这个抽象的金字塔概念之前，让我们先看一个生活中比较常见的例子。比如你是一个木匠，你准备做点科研，造个什么木制品出来，这个作品相当精妙，以至于需要十几种甚至更多的工具来帮助你完成，假定这些工具目前放在你的车库。\n现实中，当你用工具的时候你并不会总是去车库找工具，你可能会先找一个小盒子将你认为在不远的将来你可能会用到的工具先一次性取出来。此外你甚至不会说是每次用什么工具都会去盒子里面找一下，一般你总会保证伸手就够得着的地方有最近需要使用的那么几件工具，此外，你的手上可能握着正在使用的一到两件工具。你会发现，从车库到盒子到手够得着的位置再到你的手上，能够维护的工具数量越来越少，车库总是能够放上很多的工具，箱子里面可能有十几个，在身边就能够着的区域可能就只能放四五个了，手上可能拿两个工具已经是极限了。\n但是不可否认，这的确会对你的工作效率产生很大的提升，其实这得益于两个定理，第一个，现在被使用的工具在不远的未来更可能会被用到，和这个很好理解，同一个工具你可能会用很长一段时间；一个工具被用到，与它相对来说比较接近，比如功能相似的一些工具在不远的将来更有可能被用到，比如各种型号的木头抛光器。\n当然了，有时候你会把手上的工具换下来，然后可能会发现工具没在旁边，你可能还是会去翻盒子，如果盒子里面找不到，比如你压根儿就忘了从车库里取出来，你那么你就不得不跑到车库里面再取一遍了。而且如果还有其他人也依赖于这个车库来获取工具的话，你可能还得及时的将工具还回去，如果每次用完就还回去，你可能会在车库和工作室之间跑来跑去，很影响工作效率；但是如果每次都是到最后作品完成再还回去，可能其他人要抱怨了。聪明的你应该又看到另一个** Trade off**的影子了吧，哈哈。\n让我们再回到之前的金字塔底部，我们现在好像瞥见到了两个极端，一个是金字塔的底部，另一个则是金字塔的顶端。便宜，大容量但是速度慢；速度足够快但是价格高昂且容量很小。好在金字塔不止有底部和顶端，它还有中间的部分，这也是我们的Trade off策略得以游走的空间。我们从金字塔的最底部慢慢向上攀爬探索：\n   越过磁盘，首先我们可能接触的内存，虽然断电后数据就会丢失，但是其访问速度相较于磁盘已经有了质的提升，当然了，相对于磁盘，其价格更高，容量也要小很多，在1TB的固态硬盘充斥在人们的生活中时，我们通常可以操作的内存空间一般只有8G，16G等；很多的操作系统也通过虚拟内存突破了物理内存的限制，所以一般16G的内存对于绝大多数人来说都已经足够了。\n   我们继续向上攀爬，此时我们会遇到称为高速缓存的东西，一般有两级，我们称之为二级缓存和以一级缓存，实际上我们的CPU尝试加载数据时，并不会直接和我们的内存打交道，我们首先会将需要访问的内存连同周边临近的内存区域先加载到二级缓存中，然后再加载一部分到一级缓存中。现在当CPU尝试去加载数据的时候，花在IO上的时间就很短了。\n   然后就是寄存器了，如果你写过汇编或者有看过反编译后的Java的字节码指令，你可能会看到，我们是如何精细地一个一个存储单元的进行访问和管理的。空间很小，但是因为他们是最接近CPU的位置，它们的存在让我们的指令序列得以流畅的执行，而不必每次都花费大量时间等待IO。\nJava作为一门编程语言以及一个平台，其底层实现的时候，其实也逃不掉这些模式的束缚。只不过我们上面讨论的是硬件资源上的一些Trade off，Java内存模型是在这个基础之上又进行了一层抽象，但是其内在原理还是相通的。\n本系列文章在编写时大量参考了《Java并发编程艺术》一书，原书将Java内存模型放在第三章，将Java语言中的一些特性以及实现原理，比如synchronized，volatile等关键字放在第二章。当我在准备第二篇文章的时候，老师感觉写起来不是很顺畅，因为里面有很多的概念其实是依赖于Java内存模型中的很多内容的。所以就调整了一下顺序，将JMM提到前面来写一下。\n目录 Java内存模型 在并发编程中，我们有两个问题需要解决，当多个线程共同合作完成一个或者多个特定问题时，我们定义好线程之间如何进行通信以及如何进行同步的。通信是指线程之间如何交换信息，包括获取处理的入参输出处理的结果等等。线程之前通信的方式两种，消息传递和共享内存。\n其中消息传递这种模式，在一些移动开发时可能会遇到，比如Android开发时，我们会有一个UI线程，还会有一些子线程，子线程一般用于去获取数据，比如调用一个接口获取数据，而主线程我们也叫UI线程的话，顾名思义，主要工作是进行UI的渲染。我们不希望在UI线程里面去进行IO操作，这样可能会导致线程阻塞相当长的时间，界面就无法进行组件的渲染，更无法响应用户的操作，这对用户来说是完全不可接受的。真因为这样我们才会在子线程中做IO相关的操作。当子线程成功加载好数据之后，我们会使用一种消息传递的机制来通知UI线程，我已经成功获取了数据，你可以拿最新的数据进行渲染了。\n相比于消息传递，共享内存这种方式来进行数据共享就相对来说要常见的多了。多个线程往往通过读写内存中的公共状态来进行隐式通信。\n不管是消息传递还是共享内存，我们都需要做一件事情，那就是指定一个数据的同步访问机制，避免由于大家同时对数据进行读写导致最终获得一个错误的结果。在消息传递模型中，消息的接收一定在消息的发送之后，因此共享数据的访问一直都是串行的，同步是隐式进行的。在共享内存模型中，数据访问的顺序无法预见，所以程序员必须显式的指定某个方法或者某个代码片段需要在线程之间互斥的执行，同步是显式进行的。\nJava并发采用的是共享内存模型，默认情况下，Java线程之前的通信总是隐式进行的，整个通信过程对程序员完全透明，如果程序员没有意识到这个并且不手动加以控制就不可能得到正确的结果。\nJava内存模型的抽象结构 Java定义了一套抽象的模型来控制线程间在进行内存共享时共享内容在各个线程之间的可见性，这个模型决定了一个线程对一个共享变量的写入何时对另一个线程可见。\n从抽象角度来看，JMM定义了主存和线程工作内存之间的关系。线程间的共享变量存储在主存中，而每一个线程都有一个线程私有的本地内存，我们也称之为工作内存，工作内存中存储了该线程读写共享变量的副本。\n工作内存是JMM的一个抽象概念，并不是真实存在的，它涵盖了寄存器，高速缓存，写缓冲区以及其他硬件以及编译器优化。\n 假定两个线程A，B同时访问一个共享变量var，根据JMM，除了主存中的数据var，线程A，B在工作内存中还存在两个副本，var-A，var-B。当线程A，B对共享变量进行读取或者修改时，他们直接操作工作内存中的副本。\n那么当其中一个线程对数据进行了更新时，如果另一个线程想要读取到最新的结果，我们就必须将更新过后的值刷新到主内存中去，然后另一个线程在读取数据时，不能直接从工作内存的副本中读取过期的数据，其必须直接从主存中加载最新的结果。而JMM正是通过控制朱迅与每个线程的本地内存之间的交互，来为Java程序员提供内存可见性的保证。\n指令重排序 在执行程序时，为了提高性能，编译器和处理器常常会对指令做重排序，其分为以下三种类型：\n 编译器优化的指令重排序 - 编译器在不改变单线程语义的情况下，可以重新安排语句的执行顺序 指令级并行重排序 - 如果多条指令之间不存在数据依赖性，处理器可以改变语句对应机器指令的执行顺序。 内存系统的重排序 - 由于处理器使用缓存和读写缓冲区，使得加载和存储操作看上去可能在乱序执行。  重排序能够提升性能，但是也可能带来一些内存可见性问题，比如在单例模式实现的例子中就会讲到，指令重排序是如何导致可见性问题并使用volatile关键字来解决它的。\n对于编译器，JMM的编译器重排序规则会禁止特定类型的编译器重排序。对于指令级并行重排序，JMM的处理器重排序规则会要求Java编译器在生成指令序列时插入特定的内存屏障指令，通过这种指令来禁止特定类型的指令级并行重排序。\nJMM属于语言级的内存模型，它确保在不同比那一起和不同的处理器平台之上，通过禁特定类型的编译器重排序和处理器重排序，为程序员提供一致的内存可见性保证。\n处理器指令重排序 现代的处理器使用写缓冲区临时保存向内存写入的数据，写缓冲区可以保证指令流水线持续运行，它可以避免由于处理器停下来等待向内存写入数据而产生的延迟。同时，通过以批处理的形式刷新写缓冲区，以及合并写缓冲区对同一内存地址的多次写，减少对内存总线的占用。\n虽然写缓冲区有很多的好处，但是每个处理器上的写缓冲区仅仅对他所在的处理器可见。这个特性会对内存操作的执行顺序产生重要影响，即处理器对内存的读写操作的执行顺序，不一定与内存时间发生的读、写顺序一致。\n假定我们主存中有两个变量a，b，它们的初始值都为0；我们现在有两个处理器，Processor A，Processor B；Processor A， Processor B分别加载a，b，并将其值更改为1。我们此时期望现在两个变量值都是1，但是我们刚刚的写操作可能仅仅发生在缓冲区中。此时我们Processor A，Processor B再分别加载b，a然后将写缓冲区中的内容刷新到主存中。此时工作内存中就存在a，b两个变量的无效的副本，a=0，b=0。\n从内存操作实际发生的顺序来看，直到处理器最终刷新数据到主存中，我们的写操作才算真正执行了。我们期望的是我们分别将工作内存中的两个变量副本写回到主存中，然后再分别加载这两个变量的最新值到变量副本中，但是因为存在写缓存，导致我们的内存操作顺序发生了变化，期望的写-\u0026gt; 读，变成了读-\u0026gt;写。这种情况我们就称之为处理器的内存操作被重排序了。\n这里的关键是由于写缓冲区仅仅对自己的处理器可见，它会导致处理器执行内存操作的顺序与世界操作执行的顺序不一致。现在大多数处理器都会使用写缓冲区，因此现代的处理器都允许对写-读操作进行重排序。\n内存屏障 为了保证内存可见性，Java编译器在生成指令序列的适当位置会插入内存屏障指令来禁止特定类型的处理器重排序，Java内存模型会将内存屏障指令氛围四类，\n   屏障类型 指令示例 说明     LoadLoad Barriers Load1；LoadLoad；Load2 确保Load1数据的装载先于Load2及所有后续装载指令的装载   StoreStore Barriers Store1；StoreStore；Store2 确保Store1数据对其他处理器可见，指刷新到内存，优先于Store2及所有后续存储指令的存储   LoadStore Barriers Load1；LoadStore；Store2 确保Load1数据装载限于Store2及所有后续的存储指令刷新到内存   StoreLoad Barriers Store1；StoreLoad；Load2 确保Store1数据对其它处理器变得可见，指刷新到内存，优先于Load2以及所有后续装载指令的装载    StoreLoad barriers是一个全能型屏障，它同时具有其它三个屏障的效果。现代的多处理器大多支持该屏障。执行该屏障开销会很高昂，因为需要将当前处理器的写缓冲区中的数据全部刷新到内存中去（Buffer Fully Flush）。\nHappens-before原则 从JDK5开始，Java使用洗的呢JSR-133内存模型。JSR-133使用happens-before的概念来阐述操作之间的内存可见性。在Java内存模型中，一个操作的执行结果需要对另一个操作可见，那么这两个操作之间必须要存在happens-before关系。这里提到的两个操作既可以是在同一个线程内部，也可以是在不同线程之间。\n与程序员密切相关的happens-before规则如下：\n 程序顺序规则：一个线程中的每个操作，happens-before于该线程中的任意后续操作。即同一个线程中的多个操作天然满足happens-before规则。 监视器锁规则：对一个锁的解锁，happens-before于随后对这个锁的加锁。即当前同步代码块的结果对使用一个锁的下一个同步代码块全部可见。 Volatile变量规则：对一个volatile域的写，happens-before于随后对这个域的读。 传递性：如果A happens-before B且B happens-before C，那么A happens-before C；  两个操作之间具有happens-before关系，并不意味着前一个操作必须要在后一个操作之前执行，happens-before仅仅要求前一个操作执行的结果对后一个操作可见，且前一个操作按顺序排在第二个操作之前。\n 一个happens-before规则对应于一个或者多个编译器重排序规则和处理重排序规则。对于程序员来说，happens-before规则简单易懂，它避免程序员为了理解Java内存模型提供的内存可见性保证去学习复杂的编译器、处理器重排序规则以及这些规则的具体实现方法。\n重排序 重排序是指编译器核处理器为了优化性能而对指令序列进行重新排序的一种手段。\n数据依赖性 如果两个操作访问同一个变量，且这两个操作中一个是写操作一个是读操作，此时这两个操作之间就存在数据依赖性。数据依赖性有三种情况：\n 写后读 - 写一个变量之后再读这个位置 读后写 - 读一个变量之后再写这个位置 写后写 - 写一个变量之后再写这个位置  上面这三种情况只要发生了重排序，程序的执行结果就会发生变化。\n编译器和处理器会对操作做重排序，编译器和处理器在重排序时，会遵守数据依赖性，编译器和处理器不会改变存在数据依赖关系的两个操作的执行顺序。当然了，这里说的数据依赖性仅针对当个处理器中执行的指令序列和单个线程中执行的操作。不同处理器之间的和不同线程之间的数据依赖性不会被编译器和处理器考虑。总而言之，编译器重排序和处理器重排序不会影响单个线程的预期执行结果。\nas-if-serial语义 as-if-serial语义的意思是，不管怎么重排序，编译器和处理器重排序的目的是提高并行度，提高执行速度，但是程序的执行记过不能被改变，编译器，runtime和处理器都必须遵守as-if-serial语义。\n为了遵循as-if-serial语义，编译器和处理器不会对存在数据依赖关系的操作做重排序，因为这种重排序会改变执行结果，但是如果操作之间不存在数据依赖关系，这些操作就可能别编译器和处理器重排序。比如我们看一段计算圆面积的代码：\npublic class Solution {  public void calculateArea() {  double pi = 3.14; // A  double r = 1.0; // B  double area = pi * r * r; // C  } } ABC三个操作的依赖关系为，C依赖A，C依赖B，C不能被重排序到A和B的前面，否则程序执行的结果可能被改变。但是A和B之间没有依赖关系，编译器和处理器合一重排序A，B两个操作的执行顺序。实际执行顺序可能是A-\u0026gt;B-\u0026gt;C或者B-\u0026gt;A-\u0026gt; C，最终程序执行结果都会是3.14。\nas-if-serial语义把单线程程序保护了起来，遵守as-if-serial语义的编译器，runtime和处理器共同为编写单线程程序的程序员创建了一个幻觉，单线程程序是按照程序的编写顺序来执行的，as-if-serial语义是单线程程序员无需担心重排序会干扰他们，也无需担心内存可见性问题。\n程序顺序规则 根据happens-before的程序顺序规则，上面计算圆面积的代满足三个happens-before原则。\n A happens-before B B happens-before C A happens-before C  这里A happens-before B，但是实际执行时，B可以排在A之前执行，如果A happens-before B，Java内存模型并不会要求A一定要在B之前执行。Java内存模型仅仅要求前一个操作执行的结果内后一个操作可见。且前一个操作排在后一个操作之前，即在程序员的视角来看，代码的编写顺序，或者说是程序员理解的最终指令编译的顺序上来说，前一个操作排在后一个操作之前。\n要求前一个操作（执行的结果）对后一个操作可见意味着，如果不需要这种可见性，也就是不存在数据依赖关系的话，也即我们可以对这两个指令甚至宏观上来说这两行代码进行重排序而不影响最终的执行结果的话，JMM就认为这种重排序并不非法（not illegal）。\n在计算机中，软件技术和硬件技术有一个共同的目标，在不改变程序执行结果的前提下，尽可能高的提高并行度。编译器和处理器遵从这一目标，从happens-before的定义我们也可以看出，Java内存模型也遵从这一目标。\n重排序对多线程的影响 让我们看一个示例代码：\npublic class Solution {  int a = 0;  boolean flag = false;   public void write() {  a = 1; // 1  flag = true; // 2  }   public void read() {  if (flag) { // 3  int i = a * a; // 4  }  } } flag是一个标志，用来标识变量a是否已经被写入。这里假设有两个线程A和B，A首先执行write方法，随后线程B接着执行reader方法，线程B在执行操作4时，能否看到线程A在操作1对变量A的写入呢。答案是不一定。\n由于操作1和操作2没有数据依赖关系，编译器和处理器你可以对这两个操作重排序。同理，操作3和操作4也没有数据依赖关系（有控制依赖但是没有数据依赖，编译器处理器为了提高并行度会采用猜测执行），编译器和处理器也可以对这两个操作机械能重排序。\n当操作1和操作2重排序时，假定我们的执行顺序是2-\u0026gt;3-\u0026gt;4-\u0026gt;1，第四步我们读取的a并不是写入后的a而是初始值0，多线程的语义被重排序破坏掉了。 当操作3和操作4重排序时，操作3和操作4寸控制依赖关系，有控制依赖但是没有数据依赖时会影响指令序列的执行并行度，编译器处理器为了提高并行度会采用猜测执行来克服控制相关性对并行度的影响，已处理器猜测执行为例，执行线程B的处理器可以提前读取a并执行第四步的计算，然后将结果存储在一个重排序缓冲（Reorder Buffer，ROB）的硬件缓存中，当第三步的条件判断为真的时候，就把缓冲区中的计算结果写入结果变量中。也就是执行顺序实际上等价于4-\u0026gt;1-\u0026gt;2-\u0026gt; 3。在我们进行if条件判断之前，前读取a完成了第四步的计算，最终结果仍然是0，多线程的语义再次被重排序破坏掉了。\n在单线程中，对存在空盒子依赖的操作重排序并不会改变执行结果，这也是为什么as-if-serial语义允许对存在控制依赖的操作做重排序。但是在多线程程序中，对存在控制依赖的操作重排序，可能会改变程序的执行结果。\n顺序一致性 顺序一致性内存模型是一个理论参考模型，在设计的时候后，处理器的内存模型和编程语言的内存的模型都会一顺序一致性的内存模型作为参照。\n数据竞争与顺序一致性 在程序未正确同步是，就可能会存在数据竞争。Java内存模型规范对数据竞争的定义如下\n 在一个线程中写一个变量 在另一个线程中读取同一个变量 而且读和写没有通过同步来控制  当代码包含数据竞争时，程序的执行往往产生违反直觉的结果。此时我们只能通过真确的数据同步来保证程序每次执行都会有一致的期望的行为。我们也称作是程序的执行具有顺序一致性，程序执行的结果与该程序在顺序一致性内存模型中的执行结果相同。怎么理解呢，就是我们把位于两个不同线程中的两次执行过程进行展开，然后放到同一个线程中执行，其是等价的。\n顺序一致性内存模型 顺序一致性模型是一个被计算机科学家理想化了的理论参考模型，他为程序员提供了极强的内存可见性保证。其有两个特点\n 一个线程中的所有操作必须按照程序的顺序来执行 不管程序是否同步，所有线程都只能看到一个单一的操作执行顺序，在顺序一致性内存模型中，每个操作都必须原子执行且立刻对所有线程可见。  再概念上，顺序一致性模型有一个单一的全局内存，这个内存通过一个左右摆动的开关来实现在任何一个时刻仅连接到任意一个线程，同时，每一个线程必须按照程序的顺序来执行内存读写操作，那么也意味着在任意时间点最多只能有一个线程可以来接到内存，这样一来，所有线程的所有内存读写操作就被串行化了，在顺序一致性模型中，所有操作之间存在全序关系。\n这只是一个理论模型，它非常简单，最容易理解，但是记得我们之前说的Trade off 吗，这里其实又有提现。一个模型或者一种机制约简单，理解起来就越简单，但是同事其效率和可用性可能就越低。反过来说，一个模型或者说一个机制设计的越复杂，考虑的越多，其实效率和可用性可能就会越高，但是理解和最终实现起来肯定会花费更多的时间。我们不可能将内存模型设计成这样，那样我们的程序运行起来可能像乌龟在地上爬一样。本文开头讲的存储空间金字塔的概念就是通过一些相对复杂的机制，在既能获得最高性能的同时又保证了存储空间控制在一个合理的价格范围之内。\n假定我们两个线程A，B，每个线程分别执行三个操作A1-\u0026gt;A2-\u0026gt;A3和B1-\u0026gt;B2-\u0026gt;B3。当我们依赖于监视器锁对程序进行同步时我们的执行顺序可能是A1-\u0026gt;A2-\u0026gt;A3-\u0026gt;B1-\u0026gt;B2-\u0026gt;B3，当我们没有同步时，执行顺序可能是A1-\u0026gt; B1-\u0026gt;B2-\u0026gt;B3-\u0026gt;A2-\u0026gt;A3，所有线程都能够看到一个一致的整体执行顺序，之所以有这个保证是因为顺序一致性模型中的每个操作立即对任意线程可见。\n但是顺序一致性内存模型只是一个理论上的模型，在实际的Java内存模型中就没有和这个保证。未同步的程序在Java内存模型中不但招人那个题的执行顺序是无序的，而且所有线程可能看到的操作执行顺序也可能不一致。因为写缓冲区的关系，当前线程执行了写操作，但是数据并没有刷新到主存，这个写操作对当前线程可见，但是对其他线程是不可见的，其它线程会认为当前线程并没有做什么写入操作。只有当前线程将数据刷新到主存中时，这个写操作才能对其他线程可见。此时每个线程看到的总体的执行顺序就不是一致的。\n同步程序的顺序一致性效果 那么我们怎么在实际的内存模型中获得同理论的顺序一致性模型中一样的顺序一致性呢，答案就是同步，让我们看下使用监视器锁对示例代码进行同步之后的代码\npublic class Solution {  int a = 0;  boolean flag = false;   public synchronized void write() {  a = 1; // 1  flag = true; // 2  }   public synchronized void read() {  if (flag) { // 3  int i = a * a; // 4  }  } } 假设A线程执行了write方法，B线程执行read方法，其执行顺序是1234或者2134，可看出，其执行结果和该程序在顺序一致性模型中的执行结果相同。\n在Java内存模型中，临界区内的代码可以重排序且不会被其他线程感知，在进入临界区和退出临界区这两个关键时间点会做一些特殊的处理，是的线程在这两个时间点具有与顺序一致性模型相同的内存视图。有了同步控制，我们其提高了执行效率，也没有改变程序的执行结果。\n未同步程序的执行特性 对于未同步或未正确同步的多线程程序，Java内存模型只提供最小的安全性，线程执行时读取到的值，要么是之前某个线程写入的值，要么是默认值，它保证线程读取到的值不会无中生有。JVM在内配对象的存储空间时，首先会对内存空间清零。\n未同步程序在Java内存模型中执行时，整体上是无序的，其执行结果无法预知，未同步程序在顺序一致性模型和Java内存模型中执行特性有以下几个差异\n 顺序一致性模型保证单线程内的操作会按照程序的顺序执行，而Java内存模型不可以，前面有讲到重排序的情况。 顺序一致性模型保证所有线程只能看到一致的操作执行顺序，儿Java内存模型不可以，前面有讲到由于写缓冲区导致的多个线程看到的总体的执行顺序不一致的情况。 顺序一致性模型保证对所有内存读写操作都具有原子性，但是Java内存模型不保证对64位的long型和double型变量的写操作具有原子性。  第三个差异与处理器总线的工作机制密切相关，在计算机中，数据通过总线在处理器和内存之间传递，每次数据传递都是用过一系列步骤来完成的，我们称之为总线事务。总线事务有读写两种。读事务从内存传送数据到处理器，写数据从处理器传送数据到内存，每个事务会读写内存中一个或者多个物理内存上的连续的空间。在32位的处理器上，如果我们尝试读取或者写入64位数据，我们可能会涉及到需要将读操作或者写操作拆分成两个读操作或者写操作来执行。这两个拆分后的操作可能会被放到两个不同的总线事务中执行，此时就不能保证操作的原子性了。\nVolatile的内存语义 理解volatile特性的一个好方法就是把对volatile变量的单个读写看成是使用同一个锁对这些单个读写操作进行了同步。哈哈，我们可能又要解释下进行了同步的话会有什么效果了。\n锁的happens-before规则保证释放锁和获取锁的两个线程之间的内存可见性，这意味着对一个volatile变量的读总是能看到对这个变量的最后的写入。\n锁的语义决定了临界区代码的执行具有原子性，这意味着，即使64位的long型和double型变量，只要它是volatile变量，对这个变量的读写就具有原子性。\n如果是多个volatile操作或者类似于volatile++（其等价于读取，+1计算以及写入三个操作）这种复核操作整体上不具有原子性。\n 总而言之，volatile变量具有这些特性\n 可见性，对一个volatile变量的读，总是能够看到任意线程对这个volatile变量最后的写入。 原子性，对任意一个volatile变量的读写具有原子性，这里指的是单个的读或者写，类似于volatile++这种复合操作不具有原子性。  Volatile写-读建立的happens-before关系 从内存语义来说，volatile的写-读与锁的释放-获取有相同的内存效果：volatile写和锁的释放有相同的内存语义；volatile读与锁的获取有相同的内存语义。\n当写一个volatile变量时，Java内存模型会把该线程对应的本地内存中的共享变量值刷新到主存。\n当读一个volatile变量时，Java内存模型会把该线程对应的工作内存中的副本置为无效，线程接下来将从主内存中读取共享变量。\npublic class Solution {  int a = 0;  volatile boolean flag = false;   public synchronized void write() {  a = 1; // 1  flag = true; // 2  }   public synchronized void read() {  if (flag) { // 3  int i = a * a; // 4  }  } } 回到我们的示例程序，如果我们的flag被调整成一个volatile变量，当我们将读操作和写操作放到一起来看时，在线程B读取flag这个volatile变量是，线程A在写这个volatile变量之前所有可见的共享变量的值都将立即变得对读线程B可见。\n总而言之\n 线程A写一个volatile变量，实质上是线程A向接下来将要读这个volatile变量的某个线程发出了其对共享变量所做修改的消息 线程B读一个volatile变量，实质上是线程B接收了之前某个线程发出的，在写这个共享变量之前对共享变量所做修改的消息 线程A写一个volatile变量，随后线程B读这个volatile变量，这个过程实质上是线程A通过主内存向线程B发送消息。  volatile内存语义的实现 为了实现volatile内存语义，Java内存模型会分别限制编译器重排序和处理器重排序。\n 当第二个操作是volatile写时，不管第一个操作是什么（普通读写，volatile读写），都不能重排序，这个规则确保volatile写之前的操作不会白编译器重排序到volatile写之后。 当第一个操作是volatile读时，不管第二个操作是什么，都不能重排序，这个规则确保volatile读之后的操作不会被编译器重排序到volatile读之前。 当第一个操作是volatile写，第二个操作是volatile读时，不能重排序。  为了实现volatile的内存语义，编译器在生成字节码时，会在指令序列中插入内存屏障来禁止特定理性的处理器重排序。对于编译器来说，发现一个最优布置来最小化插入屏障的总数几乎是不可能的。因此Java内存模型采取保守策略。\n 在每个volatile写操作前面插入一个StoreStore屏障。 在每个volatile写操作后面插入一个StoreLoad屏障。 在每个volatile读操作后面插入一个LoadLoad屏障。 在每个volatile读操作后面插入一个LoadStore屏障。  以volatile写为例\n StoreStore屏障可以保证在volatile写之前，其前面的所有普通写操作已经对任意处理器可见了。这是因为StoreStore屏障将保障上面所有普通写在volatile写之前刷新到主内存。 Volatile写后面的StoreLoad屏障的多用是避免volatile写与后面可能有的volatile读写操作重排序。  因为编译器通常无法准确判断在一个volatile写的后面是否需要插入一个StoreLoad屏障，比如程序直接返回。为了保证正确实现volatile的语义，此处采取了保守策略，在每个volatile写的后面，或者在每个volatile读的前民插入一个StoreLoad屏障。从整体执行效率的角度考虑，Java内存模型最终选择了在每个volatile写的后面插入一个StoreLoad屏障。因为volatile写读的内存语义常见的一个使用模式是，一个写线程写volatile变量，多个读线程读取同一个volatile变量，当读线程数量大超过写线程数量是，选择在volatile写之后插入StoreLoad屏障将带来可可观的执行效率的提升。\n以volatile读为例\n LoadLoad屏障用来禁止处理器把上面的volatile读与下面的普通读重排序。 LoadStore屏障用来禁止处理器把上面的volatile读与下面的普通写重排序。  为了提供一种比锁更轻量级的线程之间通信的机制，JSR-133增强了volatile的内存语义，严格限制编译器和处理器对volatile变量与普通变量的重排序,确保volatile的写-读和锁的释放获取具有相同的内存语义。\n volatile仅仅保证对单个volatile变量的读写具有原子性，而锁的互斥执行的特性可以确保对整个临界区代码的执行具有原子性。在功能上，锁比volatile更强大，在可伸缩性和执行性能上，volatile更有优势。\n锁的内存语义 锁是Java并发编程中最重要的同步机制，锁除了让临界区互斥执行外，还可以让释放锁的线程向获取同一个锁的线程发送消息。\n锁的释放与获取 当线程释放锁时，Java内存模型会把该线程对应的本地内存中的共享变量刷新到主内存中。\n当线程获取锁时，Java内存模型会把该线程对应的本地内存置为无效。从而使得被监视器保护的临界区代码必须从主存中读取共享变量。\n对比锁回获取-释放的内存语义与volatile读-写的内存语义可以看出，锁获取与volatile读有相同的内存语义，锁释放与volatile写有相同的内存语义。\n总而言之：\n 线程A释放一个锁，实质上是线程A向接下来将要获取这个锁的某个线程发出了（线程A对共享变量所做修改）的消息 线程B获取一个锁，实质上是线程B接收了之前某个线程发出的（在释放这个锁之前对共享变量所做修改）的消息 线程A释放锁，随后线程B获取锁，这个过程实质上是线程A通过主存想线程B发送消息。  锁内存语义的实现 让我们看看下面这一段代码\nimport java.util.concurrent.locks.ReentrantLock;  public class Solution {  int a = 0;  volatile boolean flag = false;   ReentrantLock lock = new ReentrantLock();   public void write() {  try {  lock.lock();   a = 1; // 1  } finally {  lock.unlock();  }  }   public void read() {  try {  lock.lock();   int i = a * a; // 2  } finally {  lock.unlock();  }  } } 此处我们使用了一个ReentrantLock可重入锁实现来对我们的代码做了同步控制。我们调用lock方法获取锁，调用unlock方法释放锁。\nReentrantLock的实现依赖于Java同步器框架AbstractQueuedSynchronizer，以下简称AQS。AQS使用一个名为state的整型volatile变量来维护同步状态。这个volatile变量是ReentrantLock内存语义实现的关键。\nReentrantLock - 公平锁 当使用公平锁时，整个加锁过程如下\n \u0026ndash;\u0026gt; ReentrantLock:lock()  \u0026ndash;\u0026gt; FairSync:lock()  \u0026ndash;\u0026gt; AbstractQueuedSynchronizer:acquire(int args)  \u0026ndash;\u0026gt; ReentrantLock:tryAcquire(int acquires)        第四步真正开始加锁\npublic class ReentrantLock {  protected final boolean tryAcquire(int acquires) {  final Thread current = Thread.currentThread();  int c = getState(); // 获取锁的开始，首先读volatile变量state  if (c == 0) {  if (isFirst(current) \u0026amp;\u0026amp; compareAndSetState(0, acquires)) {  setExclusiveOwnerThread(current);  return true;  }  } else if (current == getExclusiveOwnerThread()) {  int nextc = c + acquires;  if (nextc \u0026lt; 0)  throw new Error(\u0026#34;Maximum lock count exceeded\u0026#34;);  setState(nextc);  return true;  }  return false;  } } 从源代码中可以看出，加锁方法先读取state的值\n 如果state值为0，说明这个锁没有被获取过，然后使用compareAndSet操作将这个值加上需要获取的数量，如果set成功那么加锁成功，那么加锁成功，设置当前线程为锁的拥有者并返回成功。   如果state值不为0，说明这个锁目前已经被线程持有，此时我们对比持有锁的线程和当前线程是不是同一个线程，如果不是，那么加锁失败，如果是，在未超过加锁上限Integer.MAX_VALUE的情况下，同一个线程可以再次加锁成功，这也就是** 可重入**的概念。\n当使用公平锁时，整个解锁过程如下\n \u0026ndash;\u0026gt; ReentrantLock:unlock()  \u0026ndash;\u0026gt; AbstractQueuedSynchronizer:release(int arg)  \u0026ndash;\u0026gt; Sync:tryRelease(int releases)      在第三步真正开始释放锁，下面是该方法的源代码\npublic class Sync {  protected final boolean tryRelease(int releases) {  int c = getState() - releases;   if (Thread.currentThread() != getExclusiveOwnerThread()) {  throw new IllegalMonitorStateException();  }   boolean free = false;   if (c == 0) {  free = true;  setExclusiveOwnerThread(null);  }  setState(c); // 释放锁的最后，写volatile变量state   return free;  } } 可以看出，在释放锁时，我们先判断当前线程是不是这个锁的拥有者，如果不是，无权进行锁释放，如果是，那么我们将需要释放的数量从state上减去。如果state数量不为零，此时意味着当前锁被当前线程多次重入，需要继续进行锁释放；如果state数量为零，说明当前锁已经被完全释放。\n需要注意的是，公平锁在释放锁的最后写volatile变量，在获取锁时首先读和这个volatile变量。根据volatile的happens-before规则，释放锁的线程在写volatile变量之前可见的共享变量，在获取锁的线程读取同一个volatile变量后将立即变得对获取锁的线程可见。\nReentrantLock - 非公平锁 非公平锁的释放和公平锁完全一样，所以这里仅仅分析非公平锁的获取，使用非公平锁时，加锁过程如下\n \u0026ndash;\u0026gt; ReentrantLock:lock()  \u0026ndash;\u0026gt; NonfairSync:lock()  \u0026ndash;\u0026gt; AbstractQueuedSynchronizer:compareAndSetState(int args)      在第三步真正开始加锁，让我们看看源代码\npublic class AbstractQueuedSynchronizer {  protected final boolean compareAndSetState(int expect, int update) {  return unsafe.compareAndSwapInt(this, stateOffset, expect, update);  } } 该方法以原子操作的方式更新state变量，本文把Java的compareAndSet方法调用简称为CAS。CAS方法的作用是，如果当前状态值等于预期值，则以原子方式将同步状态设置为给定的更新值。此操作具有volatile读和写的内存语义。\n让我们从编译器和处理器的角度来分析，CAS如何同时具有volatile读和volatile写的内存语义。\n前文我们提到过，编译器不会对volatile读与volatile读之后的任意内存操作重排序；编译器不会对volatile写与volatile写前面的任意内存操作重排序。组合这两个条件，意味着为了同时实现volatile读和volatile写的内存语义，编译器不能对CAS与CAS前面和后面的任意内存操作重排序。\n让我们看一下Intel x86处理器上的源代码实现\ninline jint Atomic::cmpxchg (jint exchange_value, volatile jint* dest, jint compare_value) {  // alternative for InterlockedCompareExchange  int mp = os::is_MP();  __asm {  mov edx, dest  mov ecx, exchange_value  mov eax, compare_value  LOCK_IF_MP(mp)  cmpxchg dword ptr [edx], ecx  } } 我们看LOCK_IF_MP，MP是指Multiple Processor，表示是否是多处理器，如果是多处理器，程序会为cmpxchg指令加上lock前缀，在Pentium以及之前的处理器中，其会花费昂贵的代价锁定总线，以保证只有当前处理器能够读写主存；如果程序是在单处理器上运行，那就省略lock前缀（单处理器或维护处理器内的顺序一致性）。\nintel的手册对lock前缀的说明如下\n 确保对内存的读-改-写操作原子执行 禁止该指令与之前和之后的读写指令重排序 把写缓冲区中的所有数据刷新的内存中  这里的第二点和第三点足以同时实现volatile读和volatile写的内存语义。\n总结\n 公平锁和非公平锁释放时，最后都要写一个volatile变量state 公平锁获取是首先会去读volatile变量 非公平锁获取时，首先会使用CAS更新volatile变量，这个操作同时具有volatile读和volatile写的内存语义。  锁释放-获取的内存语义的实现至少有两种方式。利用volatile变量的写-读所具有的内存语义；利用CAS所附带的volatile读和写的内存语义。\nConcurrent包的实现 ","date":"2022年3月30日","image":null,"permalink":"/post/java-concurrent-programming-02/","title":"Java内存模型"},{"categories":["Java","并发编程"],"contents":"无规矩不成方圆，为了获得并发编程带来的好处，我们需要定义一套严谨的控制机制。只有在这套机制的控制下，JVM才能够按照预期执行我们的字节码，只有了解这套机制，我们才能够编写出正确的代码得到正确的结果。\n目录 Java并发机制的底层实现原理 Java为了方便编程人员进行实现，其暴露了很多的关键字以及Api，比如synchronized，volatile以及各种Lock。我们很容易使用这些关键字以及Api实现出一些线程安全的代码，但是我们不能止步于此，要知道在软件开发的世界里，你可以在各种各样的地方找到一些Trade off的完美诠释，同样在并发编程时，相对简单的一个实现方式通常意味着你可能牺牲了一些性能，换句话说，再花同样的时间你可能能够做的更好，在保证线程安全的情况下还能够让你的程序仍然高效的执行。。所以让我们一起看下这些特性如何使用以及其背后的原理吧。\n第一个关键字 - volatile volatile，这个单词直接翻译过来是易挥发的，比如酒精，汽油等物质的挥发性。在计算机相关的属于里面，或者说是在Java语言里面，通常我们会将其翻译成易失的。我猜之所以使用这个单词是因为所有被volatile关键字标注的变量其引用的内存区域需要保证一种可见性，而JVM通过一种机制总是将最新的内容写到主存中并且也总是从主存中读取数据来实现这个，所以对于工作内存中的值，其总是很容易miss，所以才有了这么一个定义。\n这一段话里面可能涉及了很多的概念，其中非常重要的有Java内存模型相关的内容，其会在后面的文章中被覆盖到，如果暂时不清楚的话可以先跳到内存模型相关的文章中了解对应的内容。\n待补充\n","date":"2022年3月30日","image":null,"permalink":"/post/java-concurrent-programming-03/","title":"Java并发机制的底层实现原理"},{"categories":["Java","Concurrent Programing"],"contents":"在讨论并发编程的挑战之前，我想要先和大家一起回顾下并发和并行的概念，这两个概念从字面上看上去其实非常的相似，很容易搞混。\n首先两者中都有一个并字，我们姑且先讲并翻译为同时。\n如此一来，那么并发也就是同时发生，其实更加准确一点来说应该称之为同时发生一样，什么意思呢，在单核处理器时代，分时系统通过将同一个CPU核心的执行时间进行分片，然后将时间片依次分给多个执行单元，然后在用户的感知层面达到一种每一个执行单元都在同时发生一样，比如多个应用程序同时为我们的用户提供服务。\n而并行则是一个相对来说更晚一些的概念，当摩尔定律慢慢走向终结，CPU的生产厂商无法在单个的芯片上放置更多的晶体管后，他们开始转变思路，不再致力于如何在芯片上放更多的晶体管，而是为一台计算机配置更多的核心来达到同样的目的，当计算机拥有更多核心之后，我们用另外一种方式更加高效的利用计算机的算力，那就是并行。\n在此之前，我们同一时间最多只能有一个执行单元被执行，其实换句话说同一时间只会有一个线程在执行，也只有一个进程在执行，即使这个进程被拆分为多个线程。但是在拥有多核的构造之后，我们不光能够继续拥有并发带给我们的好处，此外我们甚至能让同一进程的多个可执行单元，也就是多个线程在分别在多个核心上执行。总而言之，并发就是多个执行单元在同一个核心上交替执行，并行则是多个执行单元在多个核心的每一个核心上并发。\n我们通过一张图片看下两者的区别，Erlang发明者Joe Armstrong通过一个咖啡机的例子生动的向大家解释了并行和并发之间的区别。\n目录  并发编程的挑战  上下文切换  多线程一定快吗 我们如何减少上下文切换呢   死锁  如何避免死锁   资源限制  什么是资源限制 资源限制带来的问题 如何解决资源限制问题 在资源限制的基础上进行并发编程      并发编程的挑战  前面我们简单讲了一下并发是什么。的确，并发的目的就是为了让我们的程序运行的更快，但是并不是启动的线程越多我们的程序执行的就越快，并发时，多个可执行单元之间进行切换时会有性能开销，多个线程访问一些临界资源时也会有各种竞争条件，此外我们还会受限于硬件和软件的资源限制。\n上下文切换  我们先考虑单核的情况，当我们在单核上执行多线程时，CPU通过给每个线程分配CPU时间片实现这个机制。时间片是CPU分给各个线程的执行时间，它通常比较短，比如几十毫秒，然后CPU通过不停的切换线程执行，让用户感觉多个线程是在同时执行的。\nCPU的确通过时间片分配算法来实现了循环执行任务，当前任务执行一个时间片之后会切换到下一个任务，但是在切换之前，我们需要保存上一个任务的执行状态，只有这样，当下一次切换回这个任务时，我们才能够重新加载这个任务的状态并继续执行。而这个保存任务状态然后再加载并执行的过程就是上下文切换。\n就比如我们在和一个人聊天的时候，突然另一个电话打进来了，我们可能需要先和当前这位聊天的小伙伴说一声抱歉，然后记住你们目前讨论的问题是什么，然后转而先去接这个临时打进来的电话，等这个电话结束，我们可能会再找到之前聊天的那个小伙伴，继续之前讨论的话题。显然，这样的切换是会影响到你们沟通的效率的，你应该经常问道或者听别人问道过，\u0026ldquo;诶，我们刚刚讲到哪儿了？\u0026quot;，同理，这样的上下文切换也会影响多线程的执行速度。\n多线程一定快吗  事实上，当我们的计算量小于某一个量级时，拆分更多的线程可能最终的效率还不如让整个计算过程串行执行。因为频繁的上下文切换反而浪费了更多时间，这些时间最终随着线程数的增加反而超过了多核并行计算带来的收益。我们后面也会讲到，如何基于IO密集型还是CPU密集型的处理流程来设置恰当的线程数量来保证我们的程序有更好的性能。\n我们如何减少上下文切换呢  减少上下文切换的方式有很多，比如适当控制线程数量，使用CAS算法，无锁并发编程以及协程等。\n 控制线程数量 - 避免创建大量不需要的线程，比如整个任务是CPU密集型的，明明CPU已经满负荷运行了，已经以最大的计算能力处理我们的数据了，此时我们创建过多的线程，可能会适得其反，因为这时候CPU不光要忙着计算最终的结果，还需要频繁的进行上下文切换，反而拖慢了整体的效率。 CAS算法 - 全称是Compare And Swap，使用CAS算法时，我们不会尝试去获取锁，线程也就不会阻塞，也意味着我们不会失去对CPU的使用权，那么我们也就不需要进行上下文切换了。 无锁并发编程 - 多线程竞争锁时，会引起上下文切换，所以如果我们能够使用一些办法来避免使用锁或者避免锁竞争的话，就可以避免切换。比如Java 5引入的ConcurrentMap的概念以及其实现ConcurrentHashMap，就可以通过使用分段锁来提高并发度，从而避免大量的锁竞争。 协程 - 在单线程中实现多任务的调度，并在单线程里维持多个任务的切换。  死锁  当我们面对并发编程时可能遇到的竞争条件时，我们有时需要使用锁来对资源的访问进行控制，否则我们程序的执行结果就可能是错误的，花费了大量的算力最终得到的却是一个没有意义的结果。\n锁使用简单，易于理解，但是同时也会给大家带来一定的困扰，其中一个就是死锁。一旦产生死锁，就会造成系统功能不可用，而且很难恢复。死锁发生通常意味着我们访问资源的顺序出现了问题。比如线程A访问资源1，2；线程B则尝试访问资源2，1；如果A获取到了控制资源一访问的互斥锁，同时B获取到了资源2的锁那么， 此时线程A，B都将无法再继续向下执行，此时我们就称作是发生了死锁。\n如何避免死锁   避免同一个线程获取多个锁。我们编程时很难全盘考虑，如果一个线程可以获取多个锁，那么一旦我们疏忽了，没有控制好资源访问的顺序，那么就有可能发生死锁。 避免一个线程在锁内占用多个资源。 使用带超时的锁。加锁时，我们可以给上锁的过程设置一个超时时间，这样如果真的有死锁的状态发生，超时时间结束之后，至少可以保证一个线程能够正常地失败，其持有的锁得到释放，而另一个线程就可以获取到这个锁并继续执行了。  资源限制  什么是资源限制  任何一台计算机，其能够提供的资源是有限的，比如，带宽，磁盘IO，CPU，内存，各种类型的连接数等等。拿带宽来说，如果链路的带宽是2M每秒，启动十个线程进行下载，总体的下载速度不会变成20M每秒。因为运营商给我们保证的上行、下行速度是一定的。\n资源限制带来的问题  我们尝试使用并发编程是因为我们尝试将代码中原本串行执行的部分编程并发执行，但是如果调整之后，由于资源限制问题，其任然是在串行执行，那么我们可能反而达不到原来的效果了。像我之前提到的一个CPU密集型的任务，当你增加线程数量时，只不过白白花费了CPU的算力做上下文切换罢了。\n如何解决资源限制问题  通常我们可以通过两种方式解决这个问题\n 第一种 - 增加更多的硬件，比如对于IO密集型的任务，我们可以在保持算力不变的情况扩充核心数量，比如之前是四核的，我们现在换成八核，十六核，这样我们就可以让更多的线程同时并行执行。对于CPU密集型的任务，我们可以在算力不变的情况下减少CPU的核心数，因为有一些线程池的实现会把CPU核心数作为线程池大小计算的依据，或许，减少了CPU核心数量，总体的线程数量反而变少了，那么浪费在线程上下文切换上的算力也反而变少了。 第二种 - 调整软件实现方式，我们有很多的池化技术，线程池，连接池，对象池等等，就是因为在资源创建和销毁的过程中也是很消耗资源的，包括内存以及CPU的计算时间，所以将这些资源缓存起来，使用特定的策略进行维护可能会是你获得意想不到的收益。  在资源限制的基础上进行并发编程  当我们进行并发编程时，我们必须对自己的资源和自己将要处理的任务有一个清晰的认知。我处理的究竟是CPU密集型的任务还是IO密集型的任务。我的硬件资源里面，带宽，CPU，磁盘IO，内存大小，究竟哪一个才是我第一个遇到的瓶颈。这样我们才能对症下药，获得更好的性能。\n","date":"2022年3月28日","image":null,"permalink":"/post/java-concurrent-programming-01/","title":"并发编程的挑战"},{"categories":["Tutorials","Algorithms"],"contents":"其实很早就想要写一篇动态规划相关的文章，把这个非常棒的算法或者说是一种问题思考方式推荐给更多的人，不论你是程序员还是其他任何职业的从业人员，了解动态规划都会对你或者说你看待一个问题的方式或多或少产生一些影响，因为它真的太强大了。\n那么为什么我会这么觉得呢?\n第一，动态规划几乎可以说是分治在现实世界里面最优雅的一种表达方式。当我们面对一个非常复杂的问题时，如果这个问题能够划分为子问题并逐个击破，那么此时不用想太多，动态规划大概率是解决这个问题的一个最好的工具了，不论是指导你对这个问题进行快速的分析还是最终作为实际的解决方案，动态规划绝对会让你的眼前一亮。\n第二，动态规划不会止步于问题分析以及给出一个递归的解决方案。的确，当我们使用动态规划时，当我们明确了我们的状态以及状态迁移方程，我们很容易得到一个基于递归的解决方案。这是动态规划的一大优点所在，即你不需要将一整个问题放到你的脑海中完完整整的想清楚，你只需要瞥见其中的规律，便可以快刀斩乱麻，轻松地解决一个非常复杂的问题；但是递归虽好，如果有时候使用不当，你的程序可能需要大量的资源，执行大量的计算，花费更多的时间才能得到最终的结果；好在动态规划并没有止步于仅仅给出一个递归的解决方案，除此之外，我们只要使用一些其他的方法或者依赖一些恰当的数据结构，就能够得到一个高效到令人拍案叫绝的解决方案。\n初次接触到动态规划时，我甚至都不知道自己接触了这个概念，其实就是大家可能经常接触到的一个数学问题，斐波那契数列。\n 斐波那契数列（Fibonacci sequence），又称黄金分割数列，因数学家莱昂纳多·斐波那契（Leonardo Fibonacci）以兔子繁殖为例子而引入，故又称为“兔子 数列”，指的是这样一个数列：1、1、2、3、5、8、13、21、34、……在数学上，斐波那契数列以如下被以递推的方法定义：F(0)=0，F(1)=1，F(n)=F(n - 1)+ F(n - 2)（n ≥ 2，n ∈ N*）\n 你可能会问道，这个斐波那契数列和动态规划又有什么关系呢，哈哈，的确，乍一看，可能这两者之间并没有太大联系，不过这并不奇怪，主要是因为我们已经跳过了动态规划的部分，转向了当我们使用动态规划给这个问题求解时所得到的最终的解决方案，所以我们已经看不到动态规划的影子了，也就无从探究它的魅力了。\n那么怎么办呢，我们可能从这个问题的源头开始说起，我这里不会举这个百度百科或者维基百科上出现的兔子问题，我所要想你展示的是另一个非常有趣的问题\u0026ndash;爬楼梯。\n 爬楼梯问题，假设有十级楼梯，你每次移动时，要么移动一级台阶，要么移动两级台阶，请问从楼梯的底部到顶部你一共有多少种可能的方式？\n 当我们拿到这个问题时，我们的大脑可能会不由自主的开始枚举所有可能的结果，比如每一步都只向上移动一级台阶是一种可能的走法，每一步都向上移动两级台阶是一种走法，前面四步每一步都移动两级台阶，然后第五步第六步分别移动以及台阶又是一种走法。如此循环往复尝试罗列所有的可能的结果，但是你很快就会发现，想要罗列出所有结果对你来说太难了，此外你也应该已经注意到了，现在还仅仅是十几台阶，如果是二十级三十级甚至更多，使用这种枚举的方式几乎是不可能行得通的。\n此时，动态规划的思想就很容易应用到这个问题上了。来，让我们转换一下思路，加入你现在只剩最后一次移动就到达第十级阶梯了，那么你可能的情况是什么呢，你会发现此时只会有两种结果，那就是你要么在第九级阶梯，此时你向上移动一级阶梯就可以到达终点了；要么你在第八级阶梯，此时你向上移动两级阶梯同样可以到达终点。那么换句话说，你想要到达终点，就必须先到达第八级阶梯或者第九级阶梯，也意味着，走到终点的可能的走法等价于走到第八级阶梯的走法加上走到第九级阶梯的走法。同理，想要到达第九级阶梯的走法又等价于走到第七级阶梯的走法加上走到第八级阶梯的走法。一次类推，我们可以得到一个方程式f(n) = f(n - 1) + f(n - 2)。此时我们暂时不考虑所谓边界条件。\nOK我们此时已经拿到了一个所谓的方程f(n) = f(n - 1) + f(n - 2)，此时你可能又会尝试调转你的脑细胞还是进行计算了。f(10) = f(9) + f(8)、f(9) = f(8) + f(7) =\u0026gt; f(10) = f(8) + f(7) + f(8)...。你尝试对最终的结果进行展开，但是你慢慢就会发现你的脑细胞不够用了。其实此处你在做的事情就是递归求解，只是这个求解过程可能交给计算机要更加合适，留着你的脑细胞日后想其他问题吧哈哈。不过此处你就会发现递归求解过程可能出现的问题\n 当我们进行一次展开之后我们就会发现表达式f(10) = f(8) + f(7) + f(8)中出现了两个f(8)，其实这个我们也称之为子问题，我们发现这个子问题可能被重复计算了 即使我们想办法解决了重复子问题的这个缺点（动态规划很擅长这个，同时也是动态规划问题中一个很核心的步骤），我们仍然需要大量的方法调用，这是递归的很明显的一个缺点，当我们的计算量比较大时，大量的方法调用，还是会对计算性能产生很大的影响。所以我上面也提到过，动态规划并不会止步于一个递归的解决方案，除此之外，它还会更进一步，再进一步，最终得到一个迭代的解决方案，让我们的程序更加快速高效地计算出我们想要的结果。  那么让我们回到这个问题本身，我们如何利用迭代的方式得到我们最终的结果呢？让我们想一下，如果只有一级阶梯，那么显然我们只有一种走法，因此我们可以得到f(1) = 1；如果有两级阶梯，我们要么分两步走，每步向上移动一级台阶，也可以一次性向上移动两级台阶，所以我们有两种可能的走法，所以可以得到f(2) = 3\n好的，很棒到目前为止一切都很棒，也很好理解。但是如果是三级台阶呢，哈哈，脑子是不是又转不过来了。不要怕，我们已经有了一个现成的方程式可以用了对吧，就是前面提到的f(n) = f(n - 1) + f(n - 2)，那么f(3)就应该等于f(2) + f(1)结果为3，同理让我们继续求解\n* `f(1) = 1` * `f(2) = 2` * `f(3) = f(2) + f(1) = 3` * `f(4) = f(3) + f(2) = 5` * `f(5) = f(4) + f(3) = 8` * `f(6) = f(5) + f(4) = 13` * `f(7) = f(6) + f(5) = 21` * `f(8) = f(7) + f(6) = 34` * `f(9) = f(8) + f(7) = 55` * `f(10) = f(9) + f(8) = 89` * ... 完美，我们得到了最终的答案，同时你也会发现，这个等号右边的数列似乎有些眼熟，哈哈，是不是没有想到斐波那契数列居然和爬楼梯有点关系，那么如果你腿比较长，偶尔可以跨三级或者四级阶梯，你知道怎么计算了吗哈哈。\n好的第一部分就到此结束了，只是简单感受一下动态规划，接下来我会讲一下动态规划的系统性方法，其实这是翻译自博客A Systematic Approach to Dynamic Programming ，感兴趣的小伙伴也可以直接看原博客，这是我接触动态规划以来看到的最好最好的一篇博客了，后面也会将它翻译过来。\n目录  动态规划的系统性方法 简介 使用动态规划解决问题的一般步骤 我可以使用动态规划解决这个问题吗 递归和回溯非常重要 动态规划的方法  Memoization - 自顶向下的方式 Tabulation - 自底向上的解决方法   背包问题  我应该用动态规划解决背包问题吗 第一步 - 定义状态 第二步 / 第三步 - 定义递归关系并找到状态迁移方程 第四步 - 定义基础场景 第五步 - 实现一个朴素的递归解决方案 第六步 - 使用缓存对递归解决方案进行优化（Memoization） 第七步 - 使用自底向上的方法消除额外的递归开销（Tabulation）   一些你需要记住的重点  动态规划的系统性方法  本文中，我们将接触动态规划中两种非常重要的方法，第一种称之为Memoization，第二种则是Tabulation，说实话这两种方法很难直接翻译成中文，直译过来总感觉不是很表意，如果一定要翻译过来，我只能选用备忘录模式和表格填充算法两个名字，但是这仍然会让人根感觉怪怪的，不过，当我们真的了解了这两种方法或者技术之后，有可能会感觉有那么一点味道在里面了。\n现在的话我们还是先把这两个名词放在一边吧，其实我更加倾向于使用另外两个名字来称呼他们\n Memoization - 自顶向下的方法 Tabulation - 自底向上的方法 至于此处为什么是自顶向下又为什么是自底向上，待会儿我们就知道了，我们暂且也先把他们放在这里吧，让我们一步步探究这个然后最终我们会再回过头来看下这几个名字。  简介  动态规划这个名词乍一看去可能会有点唬人，甚至很多人面对这样的名词会望而却步，害怕又是一种什么银样镴枪头亦或是有用但是晦涩难懂，不值得花时间去研究。\n甚至有人浅尝辄止，因为有的时候尝试去找一个状态迁移方程可能并没有那么容易，还有人甚至会用一些理由来避免使用Tabulation，比如性能已经可以了，再继续下去可能代码的可读性反而大大降低了，反而增加了一些成本。\n但是在我看来这些所谓Trade off远远阻挡不了一个对它感兴趣的人，的确，这种解决问题的技术会挑战我们的固有的依赖直觉的思考方式，大多数人前期很难快速的转变自己的思路来适应它，比如递归，回溯等等。但是动态规划在现实生活中又非常有用而且当一个面试官尝试评估候选人解决问题的技巧时动态规划也显得十分有吸引力以至于候选人不得不花时间了解这个，事实证明，抛开面试不谈这也是完全值得的。\n尝试用动态规划去解决一个问题时，整个过程是可以系统化地一步一步的向前推进的，我希望在这里向你分享这样一个我自己在使用动态规划解决问题时使用的一种系统化的过程，希望这对你学习动态规划以及后期使用动态规划产生一些帮助。\n我将首先介绍使用我自己在使用动态规划处理问题时所遵循的步骤。如果你对这些步骤里面的每一个条目都已经相当了解了，或许你会想要直接找一个问题然后尝试一下，看看究竟这种方法是如何工作的。如果你尚且不熟悉这些步骤里面描述的内容，我会向你详细解释每一个步骤具体是干什么还有为什么会被我放在这个位置。\n使用动态规划解决问题的一般步骤  首先，问你自己一个问题，我真的需要使用动态规划解决这个问题吗或者说我真的可以用动态规划解决这个问题吗。\n如果我们真的能够使用动态规划解决这个问题，那么针对我们需要解决的问题\n 定义我们的状态 定义我们的递归关系，或者说是状态迁移方程 列出所有状态转换及其各自状态迁移的条件 定义我们的基本情况 实现一个朴素的递归解决方案 使用自顶向下的方法（Memoization）对我们递归的解决方案进行优化 使用自底向上的方法（Tabulation）消除递归的开销  在我们开始按照这些步骤进一步探索之前，让我们先重申一下几个点\n 第一，这一篇文章只是对动态规划所涵盖的主要概念的一些概括，你会在其他的一些博客或者课程里面看到针对动态规划更加准确详细严格的解释。 第二，如果你尝试记住这篇文章里面出现的动态规划的解决方案或者尝试记住更多的动态规划解决方案对于你在未来解决其他的一些动态规划问题可能并没有什么帮助，学习如何一步步得到最终的解决方案才能从根本上理解并学会使用动态规划。 第三，我不是一个动态规划的专家，本文中所涵盖的任何提示或者技巧性的内容只是我作为一个计算机专业的学生在学习动态规划的过程中发现的。  我可以使用动态规划解决这个问题吗  首先，让我们再尝试描述一下动态规划究竟是什么。简而言之，动态规划是一种解决复杂问题的技术，旨在通过首先解决这个复杂问题的子问题，解决子问题时，又可以使用同样的思路，首先解决这个子问题的子问题，如此循环往复达到最终解决整个复杂问题，这里需要声明的是每一个子问题，我们最多只会求解一次。\n动态规划被广泛用于解决与优化相关的问题。 判断您的问题是否适合使用动态规划去解决的一个技巧是找到暗示优化的关键字，例如最大、最小、最长或最短。\n一个问题是否能够使用动态规划进行解决通常取决于这个问题是否有一个计算最优解的结构以及重叠子问题。在一些学术文档中，你可能能够找到针对这些术语的更为准确详尽的解释，但是简而言之\n 为了搞清楚一个问题是否是一个计算最优解的结构，首先你得问你自己，你能否用一种递归的关系来描述你的解决方案。如果可以，那么你就能将这个复杂问题转换为一堆更容易解决的子问题，当这些子问题被逐个解决之后，你便能够根据递归条件将你的子问题的结果进行聚合，得到最终的结果。比如前面提到的例子，斐波那契数列。 为了搞清楚当前问题是否包含重叠子问题，也需要先问你自己，当你解决这个问题的时候，你有没有发现某一些子问题被你的程序重复解决了很多遍。比如当你尝试在大脑中进行斐波那契数列的计算时，第一次展开之后你就发现，你需要计算两次f(8)。这种就可以明确的回答出，你正在解决的这个问题包含重叠子问题。  要点在于，如果你发现问题描述中提示你找到最优解，那么你就应该对你的问题进行评估，看这个问题是否有一个计算最优解的结构而且能不能找到重叠子问题，然后动态规划或许就是一个解决此问题的非常合适的方案。\n递归和回溯非常重要  在尝试用动态规划解决问题时，递归是一个非常基本的技术。在递归时，你有有一个函数，它会一层一层调用他自己直到遇到了这个问题的基本情况或者说终止条件，比如当我们计算斐波那契数列f(3)的结果时，我们就会遇到终止条件，因为f(1) = 1;f(2) = 2，这是我们很容易得到的答案。这些函数我们也就称之为递归函数。\n此外，回溯是一种使用递归来解穷举结果的技术。在这些问题中，我们必须对多种可能的结果进行评估才能够最终获得我们最优的解决方案，因为这些问题通常涉及选择的排列或组合，所以它们也被称为组合搜索问题。一个例子就是福尔摩斯最经典的语录，当我排除了所有可能性，剩下的那个就是最终的结果。在回溯中，当我们遇到了一个合理的或者不合理的结果又或者是终止条件，我们会将我们的递归流程回退一级，然后继续从其他可能的路径开始搜索，所以我们程这种方式为回溯。\n I’m Sherlock Holmes, the world’s only consulting detective. I’m not going to go into detail about how I do what I do because chances are you wouldn’t understand. If you’ve got a problem that you want me to solve, then contact me. Interesting cases only please.\nThis is what I do:\n I observe everything. From what I observe, I deduce everything. When I’ve eliminated the impossible, whatever remains, no matter how mad it might seem, must be the truth.  If you need assistance, contact me and we’ll discuss its potential.\n 让我们看一个回溯的例子，求解一组数字所有可能的排列组合，为了便于理解，这里选择的最简单的一个版本，即这组数字每一个都是唯一的。代码摘自Leet Code Permutations。\npublic class Solution {  public List\u0026lt;List\u0026lt;Integer\u0026gt;\u0026gt; subsets(int[] nums) {  List\u0026lt;List\u0026lt;Integer\u0026gt;\u0026gt; list = new ArrayList\u0026lt;\u0026gt;();  Arrays.sort(nums);  backtrack(list, new ArrayList\u0026lt;\u0026gt;(), nums, 0);  return list;  }   private void backtrack(List\u0026lt;List\u0026lt;Integer\u0026gt;\u0026gt; list , List\u0026lt;Integer\u0026gt; tempList, int [] nums, int start){  list.add(new ArrayList\u0026lt;\u0026gt;(tempList));  for(int i = start; i \u0026lt; nums.length; i++){ //递归终止条件  tempList.add(nums[i]); //附加  backtrack(list, tempList, nums, i + 1); //递归  tempList.remove(tempList.size() - 1); //清理  }  } } 这个代码整体结构非常简单，可以看到我们什么时候将数字append到列表中，然后增加开始索引并开始新的递归，注意递归结束我们还需要对递归前append的数据进行清理，通常回溯都会有这么一个标志性的清理操作。同时循环的终止条件其实就是我们的基础场景也就是我们说的到达了递归终止条件。\n好了，花点时间联系递归和回溯吧，多加练习才能适应这种一个方法会调用他自己的实现方式。一旦你适应了这种实现方式，你的代码里面可能会充斥大量这种递归函数，那时候，你就有一个新的问题了。\n动态规划的方法  正如前面提到的，动态规划的两个主要方式就是memoization（自顶向下的方式）和tabulation（自底向上的方式）。\n到目前为止，我们已经瞥见了递归和回溯在使用动态规划过程中的重要性，即将一个复杂问题拆分为这个问题更小的实例（这么说主要是为了说明复杂问题和拆分出来的子问题的相似性），也就是子问题。但是上面提到的解决方案，不论是斐波那契数列还是罗列一组不重复的数字所有可能的组合，我们都没有将其归类为动态规划的解决方案。\n对于一个朴素的递归解决方案，如果想要把它转换为一个称得上是动态规划的解决方案，我们还需要更进一步，对其进行优化，缓存每一个子问题的计算结果。再上面的定义中，重点是每个子问题我们只会解决它一次，此处的一次应该强调再强调。\nMemoization - 自顶向下的方式  Memoization等于递归加缓存。\n对一个值得使用动态规划进行解决的问题，一般它的结构表明它通常包含重叠子问题，还记得我们上面提到的斐波那契数列吗，让我们看下最简单的递归的代码实现，\nclass Solution {  public int fib(int number)  {  if(number \u0026lt;= 1) {  return number;  }   return fib(number - 1) + fib(number - 2);  } } 如果我们把整个的递归树画出来，我们会得到\n注意每一个子问题我们重复解决了多少次，比如，f(3)计算了5次，然后每一个f(3)又会重复调用两次斐波那契函数，为了解决f(3)这个子问题我们多花了很多次函数调用。现在我们来看下动态规划，我们会尝试使用一个恰当的数据结构存储我们的计算结果，从而当晚些我们需要再次计算的时候可以直接返回这个结果，这样我们就做到了对所有子问题我们仅仅解决它一次，而这就是我们所说的Memoization。现在你大概能理解我为什么之前会把它翻译成备忘录模式了吧。\nclass Solution {  public int fib(int number) {  //注意此处使用了Integer做缓存的key，由于Java Integer的缓存原因，只有在key值小于128时这段代码才能正确运行  Map\u0026lt;Integer,Integer\u0026gt; memoization = new HashMap\u0026lt;\u0026gt;();   return fib_helper(number, memoization);  }   public int fib_helper(int number, Map\u0026lt;Integer,Integer\u0026gt; memoization) {  if(number \u0026lt;= 1) {  return number;  }   return memoization.computeIfAbsent(number, fib(number - 1) + fib(number - 2));  } } 上面这段代码将会是本文想要展示的两种动态规划方法中的比较简单的一种，很好理解。当你得到一个问题的递归形式的解决方案之后，确保你正确使用了缓存，来保证你的子问题不会被重复计算。\n其实再对比一下这两个实现方式，你就会发现其实这就是计算机编程里面老生常谈的一个问题\u0026ndash;Trade off，我们在这里只不过是使用内存换时间而已。我们使用更多的内存空间存储了一些中间结果以此来达到更好的性能，这也是动态规划通常的工作方式。\n当然了，由于计算f(n)时，我们必须计算f(1)到f(n - 1)，所以此处我们将缓存换成一个长度为n的以为数组可能会更加高效。不过我们暂且先这样设计吧，之后做Tabulation时我们可以再进行下一步的优化，我们甚至不需要长度为n的一维数组，只需要常量的空间就足够了。\n有时候，使用Map或者一维数组等进行缓存可能不足以解决我们的问题，我们可能需要二维数组或者其他类型的数据结构。比如当我们解决经典的背包问题的时候，就可能需要一个二维数组。\nMemoization很棒，我们既有使用递归解决问题的优雅，每个重叠子问题我们也只解决一次。但是，并非一切都那么好，我们仍在进行大量递归调用。递归在处理器时间和内存空间上都是昂贵的，而且大多数递归函数会随着完成任务所需的递归调用次数线性消耗调用堆栈内存。\n有一些特殊类型的递归函数，称为尾递归，如果优化正确，不一定会线性增加调用堆栈。这些可以在常量调用堆栈空间上执行。无需赘述，尾递归函数在其执行结束时执行递归调用，这意味着其堆栈帧此后将无用。可以重复使用相同的堆栈内存空间来保存下一次递归调用的状态 出现的问题是处理退货地址。我们希望确保在递归树结束后，您返回到开始一系列递归调用的指令。\n递归函数总是可能遇到潜在的堆栈溢出问题，比如Python默认允许的最大栈深度是1000，如果你尝试使用带有递归的Python方法来解决一个问题，该问题的调用栈超过1000次调用的递归深度，你就会得到一个堆栈溢出异常。\nTabulation - 自底向上的解决方法  接下来我们再看下Tabulation，不同于Memoization，Tabulation致力使用另一种方式解决这个问题而且完完全全的放弃使用使用递归。不再使用递归同时也意味着我们不需要再担心方法栈溢出的问题了，而且我们也节省了递归函数调用导致的很多额外的性能开销。\n在使用Tabulation（我们有时也称为表格填充方法）进行动态规划时，我们解决所有的子问题并且将它们的结果存储在一个矩阵中。然后这些结果稍后会被使用以解决更大的子问题，如此往复直到我们解决最终的问题。也因为如此，Tabulation也被冠以另外一个名字，就是我们前面提到的，自底向上的方法，就是因为它是从递归树的底部或者说叶子节点开始然后一步一步的往上走直到到达根节点。\n与基于递归和缓存的Memoization解决方案相比，似乎Tabulation更加有点违反直觉，但是当我们考虑到大量递归调用而导致的栈内存空间线性增加的情况时，Tabulation的优势就体现出来了，Tabulation在时间复杂度和空间复杂度方面相比Memoization要更加的高效。时间复杂度体现在方法调用的减少，空间复杂度则体现在相比于使用字典缓存中间结果，一个矩阵可能更加高效，甚至我们还可以将一个矩阵优化成常量的空间，我们后面可以看到。\n如果你回头看下我们前面提到的动态规划的步骤，你会发现Tabulation是整个系统化方法的最后一步，这也是因为我们会更容易得到一个Tabulation的解决方案通过先使用递归或者回溯解决这个问题然后使用Memoization缓存技术对这个粗糙的递归解决方案进行优化，然后如果可能的话我们会再做一些调整来得到一个自底向上的解决方案。晚点你会看到几个相关的技巧，现在让我们先看下究竟Tabulation是怎么工作的吧。\n我们刚开始的时候后我们提过一个名词，状态，但是我们之后没有给它一个正式的定义也没有再继续讨论在动态规划中究竟什么是状态。在我看来，状态其实就是哪些影响着每一次递归调用的输出结果的入参。同时，两个不同的状态通常也意味着两个不同的调用，又或者说是两个不同的子问题。明确了每一个状态之间的区别，我们才能知道在导向最终结果之前我们可能有哪些选择然后如何从其中全出一个最优解。在本文的结尾，我们将会联系一下如何去定义一个状态。\n因为Tabulation是一个自底向上的方法，所以我们必须先解决一个更大问题所依赖的所有子问题。如果我们不解决较小的的问题，那么我们就无从向前推进然后解决更大的问题。在Tabulation中我们通常会使用迭代而不是递归。那么我们应该从哪里开始又在那里结束呢，为了回答这个问题，让我们先看看下面这个递归关系。\n假定我们有一个函数，我们用它来求解某一个最优解问题，为了方便起见我们称这个函数为Opt, 我们假设这个问题中，我们的问题Opt(n)简单依赖于子问题Opt(n - 1)。\n这个递归关系告诉你的是，如果你不知道Opt(n - 1)的结果那么你无从得知Opt(n)的结果。这也意味着我们只能从最小值开始，比如0，然后一步一步解决每一个子问题知道我们计算出Opt(n)的结果。\n那么一个技巧就是，如果你的递归关系中展示你的状态在减少，那么你的循环条件也应该增加这样你就开始计算一个大问题依赖的更小的问题，这也就是自底向上。\n当我们尝试应用这些策略导一个实际的问题中去的时候，这些概念就会变得更加清晰，你猜怎么，我们结下来就会这么做。\n背包问题  我们现在就开始尝试应用我们的动态规划的系统化方法来解决这个著名的零一背包问题。我们的任务是，给定一个固定容量的背包以及一堆宝石，每一件宝石有特定的价值以及一个重量，我们想要从中挑选一堆最有价值的宝石带回家，不过我们有一个条件，那就是我们的背包容量是有限的。简而言之，给定n件宝石，它们的价值和重量分别是[v0,v2,v3,…,v(n-1)]，[w0,w1,w2,…w(n-1)]，此外还有一个容量限制W，现在我们需要计算出我们怎么样才能使用有限容量的背包将最有价值的宝石搬回家。\n我应该用动态规划解决背包问题吗  你注意到了吗，这个问题让我们基于特定的条件求解一个最大可能的结果。我已经嗅到了一丝求解最优解的味道，但是它真的具有最优解结构吗？\n是的，给定宝石[0, n - 1]，他们对应的价值[v0, …,v(n-1)]，对应的重量[w0, …, w(n-1)]以及总重量限制W。这个问题的解决方案可以分解为，对于任意宝石x，我可以选择拿或者不拿，如果拿了这颗宝石，我能够获取的价值就是这颗宝石的价值而且剩余的总重量限制就不得不减去当前宝石的重量；如果我不拿这颗宝石，我能够获取的价值和剩余的容量就不必发生变化，我就有更多的空间可以容纳其它的宝石了；此外不论我拿不拿这颗宝石，对于剩余的宝石，我都可以使用同样的思路继续下去。最终整个问题会因为宝石所有宝石被遍历完或者总容量被用完而终止。每遇到一颗宝石，我们的问题就会被拆分为两个子问题，而我们则根据最终要求，对两个子问题进行聚合，在这里其实就是每一次都取价值较大的那个子问题的结果。\n我知道这一段话太啰嗦了，或许一些数学公式能够更加清楚的定义这些递归关系以及这种状态转换。\n第一步 - 定义状态  那么是哪些参数会影响递归调用的结果呢，在这个问题里面，我们有两个因素会影响，那就是剩余可用的容量以及我是否会将当前这个宝石收入囊中。所以递归调用的状态将由剩余容量以及每一个时刻我们是否会将一个索引位置的宝石收入囊中。\n第二步 \u0026amp; 第三步 - 定义递归关系并找到状态迁移方程  我们会将需要去优化的一个函数定义为KS(W, i)，具体含义是，这个函数应该给我们一个当前正对第[0, i]个编号的宝石我们能够获取的最大可能的价值以及剩余的可用的容量。\n每遇到一个宝石，我们都有两种可能的选择，要或者不要。如果要，我们会对我们的状态产生影响，我们剩余可用容量会减少；此外不论要或者不要，剩余可以收入囊中的宝石也会减少一个。此外我们还需要判断这个宝石我们的剩余空间能否容纳。当我们把所有信息放到一起并尝试用数学的方式将它表示出来的时候：\n KS(W, i) = MAX( val[i] + KS(W- w[i], i-1), KS(W, i-1)) if W ≥ w[i] KS(W, i) = KS(W, i-1) else  第四步 - 定义基础场景  我们什么时候应该停止呢？一个终止条件是我们没有可用空间了(W == 0)，另一个终止条件是我们已经考虑过了所有的宝石(i == -1)，当我们满足这两个终止条件之后，我们不可能获得更多的价值了。所以终止条件就是：\n return 0 if W == 0 or i== -1  第五步 - 实现一个朴素的递归解决方案  我们已经有了实现递归解决方案所需要的所有信息，我们有递归关系，我们已经定义好了状态迁移方程，我们也找到了基础场景或者说终止条件。\npublic class Solution {  static int count = 0;  public static void main(String[] args) {  int[][] items = new int[][]{  {5, 5},  {1, 2},  {1, 2},  {1, 2},  {1, 2},  {1, 2},  {1, 2},  {1, 2},  {1, 2},  {2, 3},  {5, 10}  };   System.out.println(ks(items, items.length - 1, 12)); //24  System.out.println(count); //3405  }   private static int ks(int[][] items, int index, int capacity) {  count ++;   if (capacity == 0 || index == -1) {  return 0;  }   int takeIt = capacity \u0026gt;= items[index][0]  ? ks(items, index - 1, capacity - items[index][0]) + items[index][1] : 0;  int notTakeIt = ks(items, index - 1, capacity);   return Math.max(takeIt, notTakeIt);  } } 第六步 - 使用缓存对递归解决方案进行优化（Memoization）  根据我以往的经验，如果不先过一遍一个问题的递归的解决方案，又时候很难看出来一个问题是否有重叠子问题。我们可以运行几遍代码或者简单的在纸上画一画递归调用的序列，让我们更新我们的代码来缓存我们子问题的中间结果。\npublic class Solution {  static int count = 0;  public static void main(String[] args) {  int[][] items = new int[][]{  {5, 5},  {1, 2},  {1, 2},  {1, 2},  {1, 2},  {1, 2},  {1, 2},  {1, 2},  {1, 2},  {2, 3},  {5, 10}  };   int capacity = 12;   int[][] memo = new int[capacity + 1][items.length];   System.out.println(ks(items, items.length - 1, capacity, memo)); //24  System.out.println(count); //193  }   private static int ks(int[][] items, int index, int capacity, int[][] memo) {  count++;   if (capacity == 0 || index == -1) {  return 0;  }   if(memo[capacity][index] != 0) {  return memo[capacity][index];  }   int takeIt = capacity \u0026gt;= items[index][0]  ? ks(items, index - 1, capacity - items[index][0], memo) + items[index][1] : 0;  int notTakeIt = ks(items, index - 1, capacity, memo);   memo[capacity][index] = Math.max(takeIt, notTakeIt);   return memo[capacity][index];  } } 对比上一种方式你就会发现递归的可怕之处，在使用Memoization之前，我们的方法调用次数达到惊人的3405次，而引入缓存之后，方法调用只有仅仅193次。\n第七步 - 使用自底向上的方法消除额外的递归开销（Tabulation）  向我们之前讨论的，当我们走到这一步，我们很容易将我们的实现优化为一个表格填充的解决方案。我们只需要调整很少的代码。\n我同意作者的观点，事实上，这一步是动态规划中最难的部分，我们需要转变我们的思路，抛弃我们的直觉，转而使用其他的一些数据结构和思维模式才能进入另一番天地。\n 让我们我们调整一下我们的状态迁移方程，调整之前：\n KS(W, i) = MAX(val[i] + KS(W-w[i], i-1), KS(W,i-1)) if W ≥ w[i] KS(W, i) = KS(W, i-1) else  调整之后：\n KS[W][i] = MAX(val[i] + KS[W-w[i]][i-1], KS[W][i-1]) if W ≥ w[i] KS[W][i] = KS[W][i-1] else  我们将我们的递归关系调整成了类似矩阵运算因为Tabulation的核心就是填充矩阵。记住两个在Tabulation中的关键点。\n 对每一个状态，我们进行一次迭代。 如果你的状态值减少你的循环条件就会增加，反之亦然。  在这个例子中，我们有两个状态，在递归关系中他们的值都会减少，所以调整后的代码将会是：\npublic class Solution1 {  static int count = 0;   public static void main(String[] args) {  int[][] items = new int[][]{  {5, 5},  {1, 2},  {1, 2},  {1, 2},  {1, 2},  {1, 2},  {1, 2},  {1, 2},  {1, 2},  {2, 3},  {5, 10}  };   int capacity = 12;   System.out.println(ks(items, capacity)); //24  System.out.println(count); //1  }   private static int ks(int[][] items, int capacity) {  count++;   //其实一般情况下我们会有特殊的处理，当可用的容量为空时，或者全部items都被用完时，我们能够继续得到的价值就是0，  //也就是ks[0][*]和ks[*][0]被初始化为0是有特殊含义的，其实也就是前面的终止条件或者说基础情况  int[][] ks = new int[capacity + 1][items.length + 1];   for (int i = 1; i \u0026lt; capacity + 1; i++) {  for (int j = 1; j \u0026lt; items.length + 1; j++) {  int takeIt = 0;  if (i \u0026gt;= items[j - 1][0]) {  takeIt = items[j - 1][1] + ks[i - items[j - 1][0]][j - 1];  }   int notTakeIt = ks[i][j - 1];   ks[i][j] = Math.max(takeIt, notTakeIt);  }  }   return ks[capacity][items.length];  } } 注意我们改了什么内容：\n你的函数不再是递归的了，我们不需要传递修改后的状态，KS现在收到容量限制和宝石的列表并返回最优结果，在这种情况下，我们可以说KS现在是纯函数式的。\n注意上面的注释部分，在我们的制表方法中，基本情况被硬编码到矩阵中，有时这需要我们考虑添加虚拟行/列。如果您看到i的基本情况，它是 index==-1，但是，在矩阵上，我们不能有负索引。为了解决这个问题，我们进行了索引移位。以前是(index==-1)现在是(index==0)所以我们将在那里存储基本情况的值。\n让我们花点时间进一步分析索引移位，因为这是一种非常常见的做法。我们的递归关系显示：\n KS[W][i] = MAX(val[i] + KS[W-w[i]][i-1], KS[W][i-1]) if W ≥ w[i] KS[W][i] = KS[W][i-1] else  注意[i-1],如果我们从i = 0开始循环，这将导致越界异常，但是我们说i = 0和W = 0是我们的基本情况，没有理由计算它们，所以让我们从1开始。但是，我们需要修改引用val[i]和w[i]的方式，因为现在(i = 1)应该映射到第一个元素（位于位置0的元素），每当我们想要索引输入集合中的元素时，我们只需使用(i-1)来平衡索引移动的影响。\n请注意，唯一的主要变化是删除了用于递归的return语句，并将我们所有的递归符号更改为矩阵形式。我们将状态转换的相同逻辑包装在我们很容易知道如何生成的循环中。我们的函数中只剩下一个return语句，它为我们提供了原始问题的最终结果。这就对了！\n一些你需要记住的重点  这篇文章的确涵盖了很多的信息，尤其是最后一步的背包问题。让我们强调一下这里面最重要的一些细节：\n 动态规划是一种解决问题的技术，它倾向于通过先解决一个问题的更小的子问题有且仅有一次来达到最终解决一整个复杂问题的目的。 哪些适合使用动态规划进行解决的问题一般拥有最优解结构以及重叠子问题。 动态规划的两个主要方法就是自顶向下的方法（Memoization）和自底向上的方法（Tabulation）。 Memoization等价于递归加缓存。 递归在处理器执行时间和内存空间两个方面来说其代价都可能是很昂贵的。 在Tabulation方法中，即列表填充方法中，我们先解决所有子问题并且将结果存储在一个矩阵中，然后我们会再继续尝试解决更大的依赖于现有子问题结果的问题。 练习，练习，练习。  感谢阅读。\n","date":"2022年3月25日","image":null,"permalink":"/post/system-approach-to-dp/","title":"动态规划的系统性方法"},{"categories":["Tutorials"],"contents":"本文中，我将会简单讨论什么是静态页面生成，简单了解几种比较流行的静态页面生成器并选取其中一种名叫Hugo的静态页面生成器进行详细介绍。 事实上，您现在所看到的的内容正是基于Hugo以及其最受欢迎的主题Log Book所构建的。\n目录  什么是静态网站生成 为什么仍然需要静态网站 常见的一些静态页面生成器 Hugo / Jekyll / Hexo 准备工作  第一步 - 安装Go 第二步 - 安装Hugo 第三步 - 让我们简单认识一下Hugo CLI  hugo命令 草稿 / 未来 / 过期内容 hugo server / 热加载     开始网站搭建  第一步 - 创建一个网站 第二步 - 为你的网站添加主题 第三步 - 为你的网站添加一些内容 第四步 - 启动Hugo Server   部署我们的网站到服务器  第一步 - 换一个好看的主题 第二步 - 构建我们需要部署的静态资源 第三步 - 推送文件到远程仓库 第四步 - 使用Nginx部署网站   踩坑记录  什么是静态网站生成  所谓静态网站生成或者静态页面生成是指一种处理过程，其能够静态地生成一个网站，这个网站可能由一系列的静态的HTML页面组成。 通常，我们在本地环境通过这种流程生成静态的页面，然后我们将其上传至对应的服务器进行发布，当用户请求对应的资源时，我们直接将这些资源返回给用户进行展示。 整个过程中，不需要任何的服务器端渲染或者处理，客户端和服务器也不会有其他形式的数据传输，仅仅专递静态资源文件。\n事实上，在互联网诞生之初，第一个网站就是静态的，那时候，服务器只能返回一些非常原始的静态的页面，并没有想PHP这样的脚本语言，也不依赖于任何类似Mysql这样的数据库管理系统。\n为什么仍然需要静态网站  今天，我们已经拥有了海量的非常高效的软件和技术，比如服务端语言，数据库以及内容管理系统等，那么我们为什么还需要静态网站呢？\n 内容直接使用文件进行存储，不依赖于数据库 一个静态网站不需要服务器端渲染 静态网站比动态网站更快因为它不需要服务端渲染以及数据访问 静态网站比动态网站更加安全因为它不太可能暴露安全漏洞 使用CDN，静态网站很容易扩展 缓存静态文件资源比缓存动态数据以及页面等更加高效 对于博客这种数据，使用静态页面进行构建是再合适不过得了  常见的一些静态页面生成器  静态页面生成器，顾名思义，用来生成静态页面或者说静态网站的一种技术或者工具。 生成，那就意味着除了一般的静态内容维护之外，这些技术或者功能往往还能提供一些非常好用的功能特性，使我们的页面看起来更加的绚丽，维护起来也会更加的方便。\nJekyll \u0026amp; Hexo \u0026amp; Hug0   Jekyll - 由Github构建的一款静态内容生成器，基于Ruby，用于驱动Github Page Hexo - 一款基于Nodejs的静态内容生成器 Hugo - 一款基于Go语言的静态内容生成器，非常快速  基于Hugo \u0026amp; Nginx搭建博客  Hugo是最流行的开源静态站点生成器之一。凭借其惊人的速度和灵活性，Hugo让搭建网站再次变得有趣。\n 飞快的构建速度 - Hugo 是同类中最快的工具。每个页面的构建时间小于1ms时，网站的平均构建时间不到一秒钟。 健壮的内容管理 - Hugo 支持无限的内容类型、分类、菜单、动态 API 驱动的内容等，所有这些都无需插件。 短代码(Shortcodes) - 我们喜欢 Markdown 语法的漂亮、简洁，但有时我们需要更多的灵活性。Hugo 短代码满足了美观和灵活的需求。 内置模板 - Hugo 提供了预制的模板，可以快速完成 SEO、评论、统计和其他功能。一行代码，完成所有工作。 支持多语言 \u0026amp; i18n - Hugo 为多语言站点提供了完整的 i18n 支持，并且与 Hugo 用户喜欢的单语言站点的开发体验完全相同。 定制输出 - Hugo 允许以多种格式输出您的内容，包括 JSON 或 AMP，并使您可以轻松创建自己的内容。  准备工作  第一步 - 安装Go  ➜ ~ brew install go ➜ ~ go version 第二步 - 安装Hugo  #Hugo有很多种安装方式，此处我们使用从源码进行安装，因为我们需要Hugo Extended版本来启动scss文件的处理功能  #因为我们暂时不需要同这个仓库进行协作，所以此处设置depth为1，否则需要拉取大量的代码 ➜ ~ mkdir ~/src \u0026amp;\u0026amp; cd ~/src \u0026amp;\u0026amp; git clone https://github.com/gohugoio/hugo.git --depth=1  #构建完成之后，hugo目录应该在 ~/go/bin ➜ ~ cd hugo \u0026amp; go install --tags extended  #将$HOME/go/bin添加到执行路径中，也可以将此行代码添加到/etc/profile或者~/.zshrc文件中 ➜ ~ export PATH=\u0026#34;$PATH:$HOME/go/bin\u0026#34;  #验证是否安装成功，能多内容参见https://hugo.zcopy.site/getting-started/usage/ ➜ ~ hugo help 第三步 - 让我们简单认识一下Hugo CLI  ➜ ~ hugo help hugo is the main command, used to build your Hugo site.  Hugo is a Fast and Flexible Static Site Generator built with love by spf13 and friends in Go.  Complete documentation is available at http://gohugo.io/.  Usage:  hugo [flags]  hugo [command]  Available Commands:  completion Generate the autocompletion script for the specified shell  config Print the site configuration  convert Convert your content to different formats  deploy Deploy your site to a Cloud provider.  env Print Hugo version and environment info  gen A collection of several useful generators.  help Help about any command  import Import your site from others.  list Listing out various types of content  mod Various Hugo Modules helpers.  new Create new content for your site  server A high performance webserver  version Print the version number of Hugo  Flags:  -b, --baseURL string hostname (and path) to the root, e.g. http://spf13.com/  -D, --buildDrafts include content marked as draft  -E, --buildExpired include expired content  -F, --buildFuture include content with publishdate in the future  --cacheDir string filesystem path to cache directory. Defaults: $TMPDIR/hugo_cache/  --cleanDestinationDir remove files from destination not found in static directories  --config string config file (default is path/config.yaml|json|toml)  --configDir string config dir (default \u0026#34;config\u0026#34;)  -c, --contentDir string filesystem path to content directory  --debug debug output  -d, --destination string filesystem path to write files to  --disableKinds strings disable different kind of pages (home, RSS etc.)  --enableGitInfo add Git revision, date, author, and CODEOWNERS info to the pages  -e, --environment string build environment  --forceSyncStatic copy all files when static is changed.  --gc enable to run some cleanup tasks (remove unused cache files) after the build  -h, --help help for hugo  --ignoreCache ignores the cache directory  --ignoreVendorPaths string ignores any _vendor for module paths matching the given Glob pattern  -l, --layoutDir string filesystem path to layout directory  --log enable Logging  --logFile string log File path (if set, logging enabled automatically)  --minify minify any supported output format (HTML, XML etc.)  --noChmod don\u0026#39;t sync permission mode of files --noTimes don\u0026#39;t sync modification time of files  --panicOnWarning panic on first WARNING log  --poll string set this to a poll interval, e.g --poll 700ms, to use a poll based approach to watch for file system changes  --printI18nWarnings print missing translations  --printMemoryUsage print memory usage to screen at intervals  --printPathWarnings print warnings on duplicate target paths etc.  --printUnusedTemplates print warnings on unused templates.  --quiet build in quiet mode  --renderToMemory render to memory (only useful for benchmark testing)  -s, --source string filesystem path to read files relative from  --templateMetrics display metrics about template executions  --templateMetricsHints calculate some improvement hints when combined with --templateMetrics  -t, --theme strings themes to use (located in /themes/THEMENAME/)  --themesDir string filesystem path to themes directory  --trace file write trace to file (not useful in general)  -v, --verbose verbose output  --verboseLog verbose logging  -w, --watch watch filesystem for changes and recreate as needed  Use \u0026#34;hugo [command] --help\u0026#34; for more information about a command. 可以看到Hugo提供了很多的功能，但是在此篇博客中，我们会跳过大部分的命令，只介绍我们可能需要用到的部分。\nhugo命令  要说最常用的命令那一定是hugo了，其将你当前所在目录作为工作目录执行hugo。\n这个操作默认会基于你当前工作目录的内容生成你的静态网站，通常这些生成的静态资源放在/public目录下，当然你也可以通过手动指定publishDir来进行控制。\nhugo命令将你的网站渲染到/public目录，这样你的静态网站就可以部署到你的服务器上了。\n草稿 \u0026amp; 未来 \u0026amp; 过期内容  Hugo允许你为你想要发布的内容设置draft，publishdate，expirydate这三个属性。 顾名思义，分别表示这个待发布的内容是否是一个草稿文件，这个待发布的内容计划的发布日期，这个待发布的内容的预计过期时间。 默认情况下，Hugo不会帮你发布：\n draft: true，也就是目前尚且是草稿的内容 publishdate: future date，也就是计划在未来发布的内容 expirydate: past date，也就是已经过期的内容  当然了，Hugo也为这些特性提供了非常方便的控制方式。 你可以通过在本地开发或者生产部署时添加相应的标志来进行控制，也可以直接在你的配置文件中进行配置。 此外，在适当的时间直接调整你待发布的内容，调整其各个属性比如draft，publishdate，expirydate，似乎更加合理。\n \u0026ndash;buildDrafts #构建文件即使draft等于true \u0026ndash;buildFuture #构建文件即使publishdate是一个未来的时间，即文件尚未到达发布时间 \u0026ndash;buildExpired #构建文件即使expirydate是一个过去的时间，即文件已经过期  hugo server \u0026amp; 热加载  通常，当我们在构建我们的网站时，我们会一边开发可以一边预览我们的网站的实际效果，这通过一个简单的命令hugo server就可以搞定了。 这会为你启动一个简单的服务器将你的静态网站托管在上面，然后你就可以在浏览器中对你的网站进行预览了。\n此外，Hugo还为我们内置了热加载的功能，这意味着你不需要安装任何其他的类库或者插件就可一边进行开发一边实时的预览的网站效果。 通常，以下目录中的文件发生变更时将会触发重新构建以及热加载。\n /static/* /content/* /data/* /i18n/* /layouts/* /themes//* config  PS \u0026gt; 如果你正在准备的内容状态为draft: true，在运行hugo server命令时不要忘了加上--buildDrafts；publishdate，expirydate也是类似\n 当然了，我们也可以禁用掉热加载\n➜ ~ hugo server --watch=false  #或者  ➜ ~ hugo server --disableLiveReload  #或者 ➜ ~ echo \u0026#34;disableLiveReload: true\u0026#34; \u0026gt;\u0026gt; config.yaml 开始网站搭建  第一步 - 创建一个网站  很简单，直接运行hugo new site {your site name}\n➜ ~ hugo new site serius Congratulations! Your new Hugo site is created in ~/serius.  Just a few more steps and you\u0026#39;re ready to go:  1. Download a theme into the same-named folder.  Choose a theme from https://themes.gohugo.io/ or  create your own with the \u0026#34;hugo new theme \u0026lt;THEMENAME\u0026gt;\u0026#34; command. 2. Perhaps you want to add some content. You can add single files  with \u0026#34;hugo new \u0026lt;SECTIONNAME\u0026gt;/\u0026lt;FILENAME\u0026gt;.\u0026lt;FORMAT\u0026gt;\u0026#34;. 3. Start the built-in live server via \u0026#34;hugo server\u0026#34;.  Visit https://gohugo.io/ for quickstart guide and full documentation. 让我们来简单看下我们的目录结构\n➜ ~ hugo cd serius \u0026amp;\u0026amp; ls -al total 8 drwxr-xr-x 9 hugo staff 288 Mar 22 21:12 . drwxr-xr-x 7 hugo staff 224 Mar 22 21:12 .. drwxr-xr-x 3 hugo staff 96 Mar 22 21:12 archetypes -rw-r--r-- 1 hugo staff 82 Mar 22 21:12 config.toml drwxr-xr-x 2 hugo staff 64 Mar 22 21:12 content drwxr-xr-x 2 hugo staff 64 Mar 22 21:12 data drwxr-xr-x 2 hugo staff 64 Mar 22 21:12 layouts drwxr-xr-x 2 hugo staff 64 Mar 22 21:12 static drwxr-xr-x 2 hugo staff 64 Mar 22 21:12 themes 正如你所看到的的，Hugo为我们生成的目录结构非常的简单，也非常直观\n. ├── archetypes #当你使用hugo new命令区创建一个新的内容时，可以通过指定archetype来快速添加一些内容，比如标题，创建日期，draft：true ├── config.toml #你的网站的配置文件 ├── content #你的网站的主体内容 ├── data #你的数据 ├── layouts ##你的布局信息 ├── static #你的静态资源比如css，js等，其实还有一个资源文件目录assets，默认情况下不会创建这个目录，这个目录一般用于存储图片文件等 └── themes #你的网站的主体，你可以很轻松的更换一个主题，只需要将其放到这个目录并调整你的配置文件即可 PS \u0026gt; 你可以在Get Hugo Theme查看更多主题。 但是你可能需要进行购买，单个主题是49到79美元，相比之下一个捆绑包才99美元（又一个价值杠杆的标志性例子）可能更划算。 如果你有一些功能想要尝试一些比较好看的主题，你可以联系我，我现在已经购买了整个捆绑包，我这边会免费和你协作，比如直接Contribute到你的仓库（相信不收费的话应该没有违反license了吧[Doge][Doge][Doge]）。\n 第二步 - 为你的网站添加主题  #使用Git来对你的网站进行版本控制 ➜ serius git init  #使用git submodule将一个主题themes/ananke直接添加到你的themes目录下 ➜ serius git submodule add https://github.com/theNewDynamic/gohugo-theme-ananke.git themes/ananke  #更改的你的配置文件来启用这个主题，这样你的主题就添加好了 ➜ serius echo theme = \\\u0026#34;ananke\\\u0026#34; \u0026gt;\u0026gt; config.toml 第三步 - 为你的网站添加一些内容  你可以手动创建一些内容到指定的路径，比如content/\u0026lt;CATEGORY\u0026gt;/\u0026lt;FILE\u0026gt;.\u0026lt;FORMAT\u0026gt;，然后你可以手动的为其添加一些元数据，比如标题，创建时间，是否是草稿等等。\n此外你也可以使用前面提到的hugo new命令辅助你进行创建，像前面提到的，此时会使用默认的archetype帮助你创建新的内容，可以自动帮你添加标题，创建时间，是否是草稿等元数据。\n➜ serius hugo new posts/hello-hugo.md  ➜ serius echo \u0026#34;# Hello Hugo\u0026#34; \u0026gt;\u0026gt; content/posts/hello-hugo.md ➜ serius echo \u0026#34;Hello hugo, this is my first post build by hugo new command.\u0026#34; \u0026gt;\u0026gt; content/posts/hello-hugo.md  ➜ serius cat content/posts/hello-hugo.md --- title: \u0026#34;Hello Hugo\u0026#34; date: 2022-03-22T21:46:58+08:00 draft: true ---  # Hello Hugo Hello hugo, this is my first post build by hugo new command. 第四步 - 启动Hugo Server  然后我们就用启动Hugo Server来预览我们的网站了。\n➜ serius git:(master) ✗ hugo server -D Start building sites … hugo v0.96.0-DEV-b80853de90b10171155b8f3fde47d64ec7bfa0dd+extended darwin/amd64 BuildDate=2022-03-17T21:03:27Z   | EN -------------------+-----  Pages | 10  Paginator pages | 0  Non-page files | 0  Static files | 1  Processed images | 0  Aliases | 1  Sitemaps | 1  Cleaned | 0  Built in 100 ms Watching for changes in ~/Workplace/hugo/serius/{archetypes,content,data,layouts,static,themes} Watching for config changes in ~/Workplace/hugo/serius/config.toml, ~/Workplace/hugo/serius/themes/ananke/config.yaml Environment: \u0026#34;development\u0026#34; Serving pages from memory Running in Fast Render Mode. For full rebuilds on change: hugo server --disableFastRender Web Server is available at http://localhost:1313/ (bind address 127.0.0.1) Press Ctrl+C to stop 打开浏览器，输入http://localhost:1313/，就可访问你的第一个静态网站了。 部署我们的网站到服务器  好了网站已经准备好了，现在我们来将我们的网站部署到我们的服务器上。此处我先假定你已经\n 购买了一个云服务器 申请了自己的域名 购买了DNS服务并完成了对应的域名解析 进行了网站的备案 为你的域名申请了响应的证书 在你的服务器上安装了Nginx并且配置好了响应的证书  即使你没有完成上述步骤也没有关系，之后我会写一篇新的文章来详细介绍上述内容。接下来我们会在上面这些已经配置完成的基础上进行。\n第一步 - 换一个好看的主题  在我们将网站部署到服务器之前，我们可以先为它装扮一个好看的主体。你可以访问Get Hugo Theme查看更多主题， 不过这上面大多数主题都是收费的，具体怎么免费试用，应该不用我再教你一遍了吧。好了，废话不多说，直接开始吧。\n此处我们选用Hugo非常受欢迎的一款主题来进行操作，这款主题名叫Log Book. 你可以查看前面的链接来预览这个主题。 此文档中也包含了如何安装这款主题，其实很简单，之前我们是通过Git Submodule克隆了一款主题，现在我们在Get Hugo Theme上 直接下载拿到的就是主题的源文件以及对应的一个example site。\n➜ logbook-hugo ls -al total 48 drwx------@ 8 hugo staff 256 Jan 13 13:43 . drwx------@ 407 hugo staff 13024 Mar 22 20:18 .. -rw-r--r--@ 1 hugo staff 6148 Mar 18 23:54 .DS_Store -rw-r--r--@ 1 hugo staff 2074 Dec 29 12:51 changelog.md -rw-r--r--@ 1 hugo staff 84 Aug 25 2021 documentation.html -rw-r--r--@ 1 hugo staff 91 Aug 25 2021 hire-us.html -rwxr-xr-x@ 1 hugo staff 101 Jan 22 18:05 license.html drwxr-xr-x@ 4 hugo staff 128 Dec 29 12:49 themes ➜ logbook-hugo cd themes/logbook \u0026amp;\u0026amp; ls -al ➜ logbook ls -al total 32 drwxr-xr-x@ 10 hugo staff 320 Jan 4 11:54 . drwxr-xr-x@ 4 hugo staff 128 Dec 29 12:49 .. -rw-r--r--@ 1 hugo staff 6148 Mar 18 23:59 .DS_Store drwxr-xr-x@ 4 hugo staff 128 Dec 29 12:45 .forestry drwxr-xr-x@ 3 hugo staff 96 Dec 15 15:20 archetypes drwxr-xr-x@ 5 hugo staff 160 Dec 15 15:20 assets -rw-r--r--@ 1 hugo staff 2179 Dec 29 12:05 config.toml drwxr-xr-x@ 11 hugo staff 352 Dec 29 12:09 exampleSite drwxr-xr-x@ 11 hugo staff 352 Dec 29 11:55 layouts -rw-r--r--@ 1 hugo staff 491 Dec 29 12:47 netlify.toml ➜ logbook cd exampleSite \u0026amp;\u0026amp; ls -al total 24 drwxr-xr-x@ 11 hugo staff 352 Dec 29 12:09 . drwxr-xr-x@ 10 hugo staff 320 Jan 4 11:54 .. -rw-r--r--@ 1 hugo staff 6148 Jan 4 11:55 .DS_Store -rw-r--r--@ 1 hugo staff 0 Dec 15 15:20 .hugo_build.lock drwxr-xr-x@ 4 hugo staff 128 Dec 29 12:09 assets drwxr-xr-x@ 4 hugo staff 128 Jan 4 11:55 config drwxr-xr-x@ 4 hugo staff 128 Dec 26 12:20 content drwxr-xr-x@ 4 hugo staff 128 Dec 15 15:20 i18n -rw-r--r--@ 1 hugo staff 421 Dec 29 12:47 netlify.toml drwxr-xr-x@ 3 hugo staff 96 Dec 29 11:48 resources drwxr-xr-x@ 5 hugo staff 160 Dec 15 15:20 static 好了，上面就是整个主题的大致结构了。那么我们只需要\n 复制logbook到你的网站的themes目录下 复制exampleSite目录下的所有内容到你的网站的根目录 删除themes/logbook/exampleSite目录下的所有内容 更改配置文件，调整使用的主题的名称为logbook 执行hugo server -D, 打开你的浏览器，然后BOOM！！！  好的，到此我们新的主题就已经更换好了，而且，由于我们使用了log book提供的example site，所以整个网站看起来已经相当的丰富了。 然后你就可以尽情探索这一款主题了，各种风格的布局，各个不同的模块等等。\n第二步 - 构建我们需要部署的静态资源  好了，让我们回归主题，现在我们已经准备好了我们想要发布的内容，现在就是将其构建为静态资源。\n在此之前，我们需要做一点小小的配置改动。\n关于更加完整的Hugo的配置，详情请参考Hugo Configuration。 关于更加完整的Log Book的配置，详情请参考Log Book Configuration。\n此处我们需要调整的配置是baseUrl。这个配置是你的网站的基础路径。 为什么需要调整这个呢，因为我们的整个博客框架里面充斥着大量的连接，方便我们快速的进行导航，比如从主页跳转的某一篇文章，或者从主页直接跳转到你的个人信息等等。 所以我们需要告诉我们的静态资源生成器，我们的网站的根路径是什么，比如https://www.example.com/， 这样它就知道当我们跳转时，是应该从https://www.example.com/home跳转到https://www.example.com/me，而不是http://localhost:1313/me.\n#调整baseUrl为你的网站地址，比如baseURL = \u0026#34;https://www.tlst.cc/\u0026#34; ➜ themes vi /config/_default/config.toml  #生成静态文件 ➜ themes hugo -D 此时我们会发现，目录下面多了一个public文件夹，这就是我们默认的静态资源生成到的文件目录。\n第三步 - 推送文件到远程仓库  #设置你的仓库地址 ➜ serius git remote set-url origin https://github.com/{your repo here}.git  #添加并提交 ➜ themes git add -A \u0026amp;\u0026amp; git commit -m \u0026#34;{your commit message here}\u0026#34;  #推送到远程 ➜ themes git branch --set-upstream-to=origin/master master \u0026amp;\u0026amp; git push PS \u0026gt; 此处我将构件好的public目录直接推送到了远程，其实本来可以只推送内容，然后在服务器上安装Go和Hugo然后再生成相应的静态资源。 但是博主使用的Linux服务器操作系统是CentOS 7，在CentOS 7上目前没有extended版本的hugo可用。我曾尝试基于源码编译，但是执行Go install时 由于一些政策限制无法正常下载依赖的类库等无法构建。 我也曾尝试在本地用Docker启动对应的CentOS环境进行源码编译，但是最终构建失败，一些版本的依赖无法正确解析。最终只能放弃。\n 第四步 - 使用Nginx部署网站  最后一步就是使用Nginx部署我们的网站了。这一步相对来说就非常简单了，只需要将我们的源码克隆到我们的服务器上，然后再将public目录复制到Nginx默认的静态资源根目录/usr/share/nginx/html就好。\n我也曾尝试调整nginx配置将root直接指向Git Repo的public目录，但是Nginx访问时直接403 Forbidden了，目前尚未花时间进行排查。\n好了，话不多说，先直接看我的Nginx的配置文件，其中包含了证书配置的部分，如果你暂时没有申请证书，那么可以先暂时忽略。\n➜ ~ cat /etc/nginx/nginx.conf  user nginx; worker_processes auto; error_log /var/log/nginx/error.log; pid /run/nginx.pid;  include /usr/share/nginx/modules/*.conf;  events {  worker_connections 1024; }  http {  log_format main \u0026#39;$remote_addr - $remote_user [$time_local] \u0026#34;$request\u0026#34; \u0026#39;  \u0026#39;$status $body_bytes_sent \u0026#34;$http_referer\u0026#34; \u0026#39;  \u0026#39;\u0026#34;$http_user_agent\u0026#34; \u0026#34;$http_x_forwarded_for\u0026#34;\u0026#39;;   access_log /var/log/nginx/access.log main;   sendfile on;  tcp_nopush on;  tcp_nodelay on;  keepalive_timeout 65;  types_hash_max_size 4096;   include /etc/nginx/mime.types;  default_type application/octet-stream;   include /etc/nginx/conf.d/*.conf;    server {  listen 80;  server_name www.tlst.cc;  rewrite ^(.*)$ https://$host$1; #将所有HTTP请求通过rewrite指令重定向到HTTPS。  location / {  index index.html index.htm;  }  }   server {  listen 443 ssl;  server_name {your domain}; #需要将yourdomain.com替换成证书绑定的域名。  root html;  index index.html index.htm;  ssl_certificate certs/{your domain}.pem; #需要将cert-file-name.pem替换成已上传的证书文件的名称。  ssl_certificate_key certs/{your domain}.key; #需要将cert-file-name.key替换成已上传的证书密钥文件的名称。  ssl_session_timeout 5m;  ssl_ciphers ECDHE-RSA-AES128-GCM-SHA256:ECDHE:ECDH:AES:HIGH:!NULL:!aNULL:!MD5:!ADH:!RC4;  ssl_protocols TLSv1 TLSv1.1 TLSv1.2; #表示使用的TLS协议的类型。  ssl_prefer_server_ciphers on;  location / {  try_files $uri $uri/ =404;  add_header Cache-Control \u0026#34;public, max-age=3600\u0026#34;;  }   location ~ \\.(?:jpg|jpeg|gif|png|ico|cur|gz|svg|mp4|ogg|ogv|webm|htc|webp)$ {  add_header Cache-Control \u0026#34;public, s-maxage=7776000, max-age=86400\u0026#34;;  }   location ~ \\.(css|js)$ {  add_header Cache-Control \u0026#34;public, max-age=31536000\u0026#34;;  }   location /assets/fonts/ {  add_header Cache-Control \u0026#34;public, s-maxage=7776000, max-age=86400\u0026#34;;  }  } } ➜ ~ 接下来让我们部署我们的静态网站到我们的服务器。\n#克隆你的仓库 ~ git clone https://github.com/{your repo here}.git  #复制你的public文件目录到nginx的静态资源root ~ cd {your repo name} \u0026amp;\u0026amp; rm -rf /usr/share/nginx/html \u0026amp;\u0026amp; cp public /usr/share/nginx/html  #重新加载一下nginx ~ nginx -s reload OK，至此，我们的静态网站就搭建起来啦~\n踩坑记录   baseUrl的设置  通过跳转的链接发现的这个问题，改成网站基础路径就好了   CentOS 7无法构建Hugo  目前只能将构建好的public静态资源目录推送到Git Repo   构建静态资源时，也就是 hugo -D时，有一次构建出来的所有的图片文件（后缀为webp）内容均为空， 导致http请求返回Code 200但是实际的Content Length为0，一度以为是Nginx除了问题，知道最后我 执行了一下ls -al，看到了文件的实际大小。  临时的解决方案就是构建之前，先全部删除，不过之后还想研究下增量构建的，比如只构建未来发布的内容， 这个通过publishdate很容易控制的，这样的话，由于我们把public目录直接上传上去导致的每次git 提交内容巨多的问题就解决了。    ","date":"2022年3月21日","image":null,"permalink":"/post/blog-with-go-hugo-nginx/","title":"基于Hugo \u0026 Nginx搭建博客"},{"categories":null,"contents":"Lorem ipsum dolor sit amet, consetetur sadipscing elitr, sed diam nonumy eirmod tempor invidunt ut labore et dolore magna aliquyam erat, sed diam voluptua. At vero eos et accusam et justo duo dolores et ea rebum. Stet clita kasd gubergren, no sea takimata sanctus est Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet, consetetur sadipscing elitr, sed diam nonumy eirmod tempor invidunt ut labore et dolore magna aliquyam erat, sed diam voluptua. At vero eos et accusam et justo duo dolores et ea rebum. Stet clita kasd gubergren.\n","date":"2020年4月14日","image":null,"permalink":"/shop/product-3/","title":"School Bag"},{"categories":null,"contents":"Lorem ipsum dolor sit amet, consetetur sadipscing elitr, sed diam nonumy eirmod tempor invidunt ut labore et dolore magna aliquyam erat, sed diam voluptua. At vero eos et accusam et justo duo dolores et ea rebum. Stet clita kasd gubergren, no sea takimata sanctus est Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet, consetetur sadipscing elitr, sed diam nonumy eirmod tempor invidunt ut labore et dolore magna aliquyam erat, sed diam voluptua. At vero eos et accusam et justo duo dolores et ea rebum. Stet clita kasd gubergren.\n","date":"2020年3月14日","image":null,"permalink":"/shop/product-7/","title":"Blue Jacket"},{"categories":null,"contents":"Lorem ipsum dolor sit amet, consetetur sadipscing elitr, sed diam nonumy eirmod tempor invidunt ut labore et dolore magna aliquyam erat, sed diam voluptua. At vero eos et accusam et justo duo dolores et ea rebum. Stet clita kasd gubergren, no sea takimata sanctus est Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet, consetetur sadipscing elitr, sed diam nonumy eirmod tempor invidunt ut labore et dolore magna aliquyam erat, sed diam voluptua. At vero eos et accusam et justo duo dolores et ea rebum. Stet clita kasd gubergren.\n","date":"2020年3月14日","image":null,"permalink":"/shop/product-6/","title":"Cotton T-Shirt"},{"categories":null,"contents":"Lorem ipsum dolor sit amet, consetetur sadipscing elitr, sed diam nonumy eirmod tempor invidunt ut labore et dolore magna aliquyam erat, sed diam voluptua. At vero eos et accusam et justo duo dolores et ea rebum. Stet clita kasd gubergren, no sea takimata sanctus est Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet, consetetur sadipscing elitr, sed diam nonumy eirmod tempor invidunt ut labore et dolore magna aliquyam erat, sed diam voluptua. At vero eos et accusam et justo duo dolores et ea rebum. Stet clita kasd gubergren.\n","date":"2020年3月14日","image":null,"permalink":"/shop/product-1/","title":"Linen Bag"},{"categories":null,"contents":"Lorem ipsum dolor sit amet, consetetur sadipscing elitr, sed diam nonumy eirmod tempor invidunt ut labore et dolore magna aliquyam erat, sed diam voluptua. At vero eos et accusam et justo duo dolores et ea rebum. Stet clita kasd gubergren, no sea takimata sanctus est Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet, consetetur sadipscing elitr, sed diam nonumy eirmod tempor invidunt ut labore et dolore magna aliquyam erat, sed diam voluptua. At vero eos et accusam et justo duo dolores et ea rebum. Stet clita kasd gubergren.\n","date":"2020年3月14日","image":null,"permalink":"/shop/product-4/","title":"Pink T-Shirt"},{"categories":null,"contents":"Lorem ipsum dolor sit amet, consetetur sadipscing elitr, sed diam nonumy eirmod tempor invidunt ut labore et dolore magna aliquyam erat, sed diam voluptua. At vero eos et accusam et justo duo dolores et ea rebum. Stet clita kasd gubergren, no sea takimata sanctus est Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet, consetetur sadipscing elitr, sed diam nonumy eirmod tempor invidunt ut labore et dolore magna aliquyam erat, sed diam voluptua. At vero eos et accusam et justo duo dolores et ea rebum. Stet clita kasd gubergren.\n","date":"2020年3月14日","image":null,"permalink":"/shop/product-2/","title":"Side Bag"},{"categories":null,"contents":"Lorem ipsum dolor sit amet, consetetur sadipscing elitr, sed diam nonumy eirmod tempor invidunt ut labore et dolore magna aliquyam erat, sed diam voluptua. At vero eos et accusam et justo duo dolores et ea rebum. Stet clita kasd gubergren, no sea takimata sanctus est Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet, consetetur sadipscing elitr, sed diam nonumy eirmod tempor invidunt ut labore et dolore magna aliquyam erat, sed diam voluptua. At vero eos et accusam et justo duo dolores et ea rebum. Stet clita kasd gubergren.\n","date":"2020年3月14日","image":null,"permalink":"/shop/product-8/","title":"Travel Carrier"},{"categories":null,"contents":"Lorem ipsum dolor sit amet, consetetur sadipscing elitr, sed diam nonumy eirmod tempor invidunt ut labore et dolore magna aliquyam erat, sed diam voluptua. At vero eos et accusam et justo duo dolores et ea rebum. Stet clita kasd gubergren, no sea takimata sanctus est Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet, consetetur sadipscing elitr, sed diam nonumy eirmod tempor invidunt ut labore et dolore magna aliquyam erat, sed diam voluptua. At vero eos et accusam et justo duo dolores et ea rebum. Stet clita kasd gubergren.\n","date":"2020年2月14日","image":null,"permalink":"/shop/product-5/","title":"Travel Bag"},{"categories":null,"contents":"H1 Heading H2 Heading H3 Heading H4 Heading H5 Heading H6 Heading  Paragraph Did you come here for something in particular or just general Riker-bashing? And blowing into maximum warp speed, you appeared for an instant to be in two places at once. We have a saboteur aboard. We know you’re dealing in stolen ore. But I wanna talk about the assassination attempt on Lieutenant Worf. Could someone survive inside a transporter buffer for 75 years? Fate. It protects fools, little children, and ships.\n Emphasis :  Did you come here for something in particular or just general Did you come here for something in particular Did you come here Did you come here for something in particular Did you come here for something in particular  Did you come here for something in particular URLs and URLs in angle brackets will automatically get turned into links. http://www.example.com or http://www.example.com and sometimes example.com (but not on Github, for example).   Ordered list  you appeared for an instant to be in two places at once. We have a saboteur aboard. you appeared for an instant to be in two places at once.   Unordered list  Quisque sem ipsum, placerat nec tortor vel, blandit vestibulum libero. Morbi sollicitudin viverra justo Blandit vestibulum libero. Morbi sollicitudin viverra justo Placerat nec tortor vel, blandit vestibulum libero. Morbi sollicitudin viverra justo   Code and Syntax Highlighting : var s = \u0026#34;JavaScript syntax highlighting\u0026#34;; const plukDeop = key =\u0026gt; obj =\u0026gt; key.split const compose = key =\u0026gt; obj =\u0026gt; key.split alert(s); var s = \u0026#34;JavaScript syntax highlighting\u0026#34;; const plukDeop = key =\u0026gt; obj =\u0026gt; key.split const compose = key =\u0026gt; obj =\u0026gt; key.split alert(s);  Buttons Button  Quote  “Did you come here for something in particular or just general Riker-bashing? And blowing into maximum warp speed, you appeared for an instant to be in two places at once.”\n  Notice : This is a simple note.\n This is a simple tip.\n This is a simple info.\n This is a simple warning.\n  Tab :  Title goes here Did you come here for something in particular or just general Riker-bashing? And blowing into maximum warp speed, you appeared for an instant to be in two places at once. We have a saboteur aboard. We know you’re dealing in stolen ore. But I wanna talk about the assassination attempt on Lieutenant Worf.  Title goes here Lorem ipsum dolor sit amet, consetetur sadipscing elitr, sed diam nonumy eirmod tempor invidunt ut labore et dolore magna aliquyam erat, sed diam voluptua. At vero eos et accusam et justo duo dolores et ea rebum. Stet clita kasd gubergren, no sea takimata sanctus est Lorem ipsum dolor sit amet. Lorem ipsum dolor sit amet, consetetur sadipscing elitr, sed diam nonumy eirmod tempor invidunt ut labore et dolore magna aliquyam erat, sed diam voluptua. At vero eos et accusam et justo duo dolores et ea rebum. Stet clita kasd gubergren, no sea takimata sanctus est Lorem ipsum dolor sit amet.  Title goes here Lorem ipsum dolor sit amet, consetetur sadipscing elitr, sed diam nonumy eirmod tempor invidunt ut labore et dolore magna aliquyam erat, sed diam voluptua. At vero eos et accusam et justo duo dolores et ea rebum. Stet clita kasd gubergren, no sea takimata sanctus est Lorem ipsum dolor sit amet.\nLorem ipsum dolor sit amet, consetetur sadipscing elitr, sed diam nonumy eirmod tempor invidunt ut labore et dolore magna aliquyam erat, sed diam voluptua. At vero eos et accusam et justo duo     Table :    # First Last Handle     1 Row:1 Cell:1 Row:1 Cell:2 Row:1 Cell:3   2 Row:2 Cell:1 Row:2 Cell:2 Row:2 Cell:3   3 Row:3 Cell:1 Row:3 Cell:2 Row:3 Cell:3     Collapse : collapse 1    Lorem ipsum dolor sit amet consectetur adipisicing elit. Lorem ipsum dolor sit amet consectetur adipisicing elit. Lorem ipsum dolor sit amet consectetur    collapse 2    Lorem ipsum dolor sit amet consectetur adipisicing elit. Lorem ipsum dolor sit amet consectetur adipisicing elit. Lorem ipsum dolor sit amet consectetur    collapse 3    Lorem ipsum dolor sit amet consectetur adipisicing elit. Lorem ipsum dolor sit amet consectetur adipisicing elit. Lorem ipsum dolor sit amet consectetur     Image  Gallery               Youtube :   ","date":"1年1月1日","image":null,"permalink":"/elements/","title":"Elements"},{"categories":null,"contents":"","date":"1年1月1日","image":null,"permalink":"/404/","title":"No Search Found"},{"categories":null,"contents":"Responsibility of Contributors Lorem ipsum dolor sit amet, consectetur adipiscing elit. Purus, donec nunc eros, ullamcorper id feugiat quisque aliquam sagittis. Sem turpis sed viverra massa gravida pharetra. Non dui dolor potenti eu dignissim fusce. Ultrices amet, in curabitur a arcu a lectus morbi id. Iaculis erat sagittis in tortor cursus. Molestie urna eu tortor, erat scelerisque eget. Nunc hendrerit sed interdum lacus. Lorem quis viverra sed\npretium, aliquam sit. Praesent elementum magna amet, tincidunt eros, nibh in leo. Malesuada purus, lacus, at aliquam suspendisse tempus. Quis tempus amet, velit nascetur sollicitudin. At sollicitudin eget amet in. Eu velit nascetur sollicitudin erhdfvssfvrgss eget viverra nec elementum. Lacus, facilisis tristique lectus in.\nGathering of Personal Information Lorem ipsum dolor sit amet, consectetur adipiscing elit. Purus, donec nunc eros, ullamcorper id feugiat quisque aliquam sagittis. Sem turpis sed viverra massa gravida pharetra. Non dui dolor potenti eu dignissim fusce. Ultrices amet, in curabitur a arcu a lectus morbi id. Iaculis erat sagittis in tortor cursus. Molestie urna eu tortor, erat scelerisque eget. Nunc hendrerit sed interdum lacus. Lorem quis viverra sed\nProtection of Personal- Information Lorem ipsum dolor sit amet, consectetur adipiscing elit. Purus, donec nunc eros, ullamcorper id feugiat quisque aliquam sagittis. Sem turpis sed viverra massa gravida pharetra. Non dui dolor potenti eu dignissim fusce. Ultrices amet, in curabitur a arcu a lectus morbi id. Iaculis erat sagittis in tortor cursus.\nMolestie urna eu tortor, erat scelerisque eget. Nunc hendrerit sed interdum lacus. Lorem quis viverra sed Lorem ipsum dolor sit amet, consectetur adipiscing elit. Purus, donec nunc eros, ullamcorper id feugiat\nPrivacy Policy Changes  Sll the Themefisher items are designed to be with the latest , We check all comments that threaten or harm the reputation of any person or organization personal information including, but limited to, email addresses, telephone numbers Any Update come in The technology Customer will get automatic Notification.  ","date":"1年1月1日","image":null,"permalink":"/privacy-policy/","title":"Our Privacy Policy"},{"categories":null,"contents":"Responsibility of Contributors Lorem ipsum dolor sit amet, consectetur adipiscing elit. Purus, donec nunc eros, ullamcorper id feugiat quisque aliquam sagittis. Sem turpis sed viverra massa gravida pharetra. Non dui dolor potenti eu dignissim fusce. Ultrices amet, in curabitur a arcu a lectus morbi id. Iaculis erat sagittis in tortor cursus. Molestie urna eu tortor, erat scelerisque eget. Nunc hendrerit sed interdum lacus. Lorem quis viverra sed\npretium, aliquam sit. Praesent elementum magna amet, tincidunt eros, nibh in leo. Malesuada purus, lacus, at aliquam suspendisse tempus. Quis tempus amet, velit nascetur sollicitudin. At sollicitudin eget amet in. Eu velit nascetur sollicitudin erhdfvssfvrgss eget viverra nec elementum. Lacus, facilisis tristique lectus in.\nGathering of Personal Information Lorem ipsum dolor sit amet, consectetur adipiscing elit. Purus, donec nunc eros, ullamcorper id feugiat quisque aliquam sagittis. Sem turpis sed viverra massa gravida pharetra. Non dui dolor potenti eu dignissim fusce. Ultrices amet, in curabitur a arcu a lectus morbi id. Iaculis erat sagittis in tortor cursus. Molestie urna eu tortor, erat scelerisque eget. Nunc hendrerit sed interdum lacus. Lorem quis viverra sed\nProtection of Personal- Information Lorem ipsum dolor sit amet, consectetur adipiscing elit. Purus, donec nunc eros, ullamcorper id feugiat quisque aliquam sagittis. Sem turpis sed viverra massa gravida pharetra. Non dui dolor potenti eu dignissim fusce. Ultrices amet, in curabitur a arcu a lectus morbi id. Iaculis erat sagittis in tortor cursus.\nMolestie urna eu tortor, erat scelerisque eget. Nunc hendrerit sed interdum lacus. Lorem quis viverra sed Lorem ipsum dolor sit amet, consectetur adipiscing elit. Purus, donec nunc eros, ullamcorper id feugiat\nPrivacy Policy Changes  Sll the Themefisher items are designed to be with the latest , We check all comments that threaten or harm the reputation of any person or organization personal information including, but limited to, email addresses, telephone numbers Any Update come in The technology Customer will get automatic Notification.  ","date":"1年1月1日","image":null,"permalink":"/terms-conditions/","title":"Our Terms And Conditions"},{"categories":null,"contents":"","date":"1年1月1日","image":null,"permalink":"/search/","title":"Search Results"},{"categories":null,"contents":"","date":"1年1月1日","image":null,"permalink":"/homepage/full-left/","title":"Tulips"},{"categories":null,"contents":"","date":"1年1月1日","image":null,"permalink":"/homepage/full-right/","title":"Tulips"},{"categories":null,"contents":"","date":"1年1月1日","image":null,"permalink":"/homepage/full/","title":"Tulips"},{"categories":null,"contents":"","date":"1年1月1日","image":null,"permalink":"/homepage/grid-left/","title":"Tulips"},{"categories":null,"contents":"","date":"1年1月1日","image":null,"permalink":"/homepage/grid-right/","title":"Tulips"},{"categories":null,"contents":"","date":"1年1月1日","image":null,"permalink":"/homepage/grid/","title":"Tulips"},{"categories":null,"contents":"","date":"1年1月1日","image":null,"permalink":"/homepage/list-left/","title":"Tulips"},{"categories":null,"contents":"","date":"1年1月1日","image":null,"permalink":"/homepage/list-right/","title":"Tulips"},{"categories":null,"contents":"","date":"1年1月1日","image":null,"permalink":"/homepage/list/","title":"Tulips"},{"categories":null,"contents":"你可以问我任何问题 或者只是打个招呼, 不想填写表单吗，你也可以通过下方的链接发送邮件\n","date":"1年1月1日","image":null,"permalink":"/contact/","title":"你可以在这里联系到我 ：）"},{"categories":null,"contents":"Gather ye rosebuds where ye may.\n  Life is a series of natural and spontaneous changes. Don’t resist them – that only create sorrow. Let reality changes be reality. Let things flow naturally way they like.\n-Tulips    My Skills \u0026amp; Experiences:  1 2 3  ","date":"1年1月1日","image":"\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\u003cimg loading=\"lazy\" decoding=\"async\" src=\"/images/author-full_hu89b7b068817a518c27453f8bc6fb846a_213454_650x0_resize_q90_h2_box.webp\" alt=\"\" class=\"img-fluid\" width=\"650\" height=\"\" onerror=\"this.onerror='null';this.src='\\/images\\/author-full_hu89b7b068817a518c27453f8bc6fb846a_213454_650x0_resize_q90_box.jpg'\"\u003e\n \n \n \n\n","permalink":"/about/","title":"你好，我是郁金香啊"},{"categories":null,"contents":"Gather ye rosebuds while ye may~\n","date":"1年1月1日","image":"\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\u003cimg loading=\"lazy\" decoding=\"async\" src=\"/images/author_hua3f03d514eef6e6af938f795778aff4d_1183262_650x0_resize_q90_h2_box_3.webp\" alt=\"\" class=\"img-fluid\" width=\"650\" height=\"\" onerror=\"this.onerror='null';this.src='\\/images\\/author_hua3f03d514eef6e6af938f795778aff4d_1183262_650x0_resize_box_3.png'\"\u003e\n \n \n \n\n","permalink":"/author/tulips/","title":"郁金香啊"}]