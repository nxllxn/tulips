---
title: "并发编程的挑战"
date: 2022-03-28T19:06:33+08:00
# post thumb
images:
- "images/java-concurrent-programing/challenges/thumb.jpg"
#author
author: "郁金香啊"
# description
description: "并发编程的挑战"
# Taxonomies
categories: ["Java","Concurrent Programing"]
tags: ["Java","Concurrent Programing"]
type: "regular"
draft: false
---

在讨论并发编程的挑战之前，我想要先和大家一起回顾下并发和并行的概念，这两个概念从字面上看上去其实非常的相似，很容易搞混。

首先两者中都有一个**并**字，我们姑且先讲并翻译为同时。

如此一来，那么并发也就是同时发生，其实更加准确一点来说应该称之为同时发生一样，什么意思呢，在单核处理器时代，分时系统通过将同一个CPU核心的执行时间进行分片，然后将时间片依次分给多个执行单元，然后在用户的感知层面达到一种每一个执行单元都在同时发生一样，比如多个应用程序同时为我们的用户提供服务。

而并行则是一个相对来说更晚一些的概念，当摩尔定律慢慢走向终结，CPU的生产厂商无法在单个的芯片上放置更多的晶体管后，他们开始转变思路，不再致力于如何在芯片上放更多的晶体管，而是为一台计算机配置更多的核心来达到同样的目的，当计算机拥有更多核心之后，我们用另外一种方式更加高效的利用计算机的算力，那就是并行。

在此之前，我们同一时间最多只能有一个执行单元被执行，其实换句话说同一时间只会有一个线程在执行，也只有一个进程在执行，即使这个进程被拆分为多个线程。但是在拥有多核的构造之后，我们不光能够继续拥有并发带给我们的好处，此外我们甚至能让同一进程的多个可执行单元，也就是多个线程在分别在多个核心上执行。总而言之，并发就是多个执行单元在同一个核心上交替执行，并行则是多个执行单元在多个核心的每一个核心上并发。

我们通过一张图片看下两者的区别，Erlang发明者Joe Armstrong通过一个咖啡机的例子生动的向大家解释了并行和并发之间的区别。

{{< image src="images/java-concurrent-programing/challenges/concurrent-and-parallel.png" caption="" alt="alter-text" height="" width="" position="center" command="fill" option="q100" class="img-fluid" title="image title" webp="false" >}}

# 目录
* [并发编程的挑战](#challenges)
  * [上下文切换](#context-switch)
    * [多线程一定快吗](#is-multi-thread-always-faster)
    * [我们如何减少上下文切换呢](#how-to-reduce-it)
  * [死锁](#dead-lock)
    * [如何避免死锁](#how-to-avoid-dead-lock)
  * [资源限制](#resource-limitation)
    * [什么是资源限制](#what-is-resource-limitation)
    * [资源限制带来的问题](#issues-caused-by-rl)
    * [如何解决资源限制问题](#how-to-solve-rl)
    * [在资源限制的基础上进行并发编程](#programing-based-on-rl)

## 并发编程的挑战 <div id="challenges" />
前面我们简单讲了一下并发是什么。的确，并发的目的就是为了让我们的程序运行的更快，但是并不是启动的线程越多我们的程序执行的就越快，并发时，多个可执行单元之间进行切换时会有性能开销，多个线程访问一些临界资源时也会有各种竞争条件，此外我们还会受限于硬件和软件的资源限制。

### 上下文切换 <div id="context-switch" />
我们先考虑单核的情况，当我们在单核上执行多线程时，CPU通过给每个线程分配CPU时间片实现这个机制。时间片是CPU分给各个线程的执行时间，它通常比较短，比如几十毫秒，然后CPU通过不停的切换线程执行，让用户感觉多个线程是在同时执行的。

CPU的确通过时间片分配算法来实现了循环执行任务，当前任务执行一个时间片之后会切换到下一个任务，但是在切换之前，我们需要保存上一个任务的执行状态，只有这样，当下一次切换回这个任务时，我们才能够重新加载这个任务的状态并继续执行。而这个保存任务状态然后再加载并执行的过程就是上下文切换。

就比如我们在和一个人聊天的时候，突然另一个电话打进来了，我们可能需要先和当前这位聊天的小伙伴说一声抱歉，然后记住你们目前讨论的问题是什么，然后转而先去接这个临时打进来的电话，等这个电话结束，我们可能会再找到之前聊天的那个小伙伴，继续之前讨论的话题。显然，这样的切换是会影响到你们沟通的效率的，你应该经常问道或者听别人问道过，"诶，我们刚刚讲到哪儿了？"，同理，这样的上下文切换也会影响多线程的执行速度。

#### 多线程一定快吗 <div id="is-multi-thread-always-faster" />
事实上，当我们的计算量小于某一个量级时，拆分更多的线程可能最终的效率还不如让整个计算过程串行执行。因为频繁的上下文切换反而浪费了更多时间，这些时间最终随着线程数的增加反而超过了多核并行计算带来的收益。我们后面也会讲到，如何基于IO密集型还是CPU密集型的处理流程来设置恰当的线程数量来保证我们的程序有更好的性能。

#### 我们如何减少上下文切换呢 <div id="how-to-reduce-it" />
减少上下文切换的方式有很多，比如适当控制线程数量，使用CAS算法，无锁并发编程以及协程等。
* 控制线程数量 - 避免创建大量不需要的线程，比如整个任务是CPU密集型的，明明CPU已经满负荷运行了，已经以最大的计算能力处理我们的数据了，此时我们创建过多的线程，可能会适得其反，因为这时候CPU不光要忙着计算最终的结果，还需要频繁的进行上下文切换，反而拖慢了整体的效率。
* CAS算法 - 全称是Compare And Swap，使用CAS算法时，我们不会尝试去获取锁，线程也就不会阻塞，也意味着我们不会失去对CPU的使用权，那么我们也就不需要进行上下文切换了。
* 无锁并发编程 - 多线程竞争锁时，会引起上下文切换，所以如果我们能够使用一些办法来避免使用锁或者避免锁竞争的话，就可以避免切换。比如Java 5引入的ConcurrentMap的概念以及其实现ConcurrentHashMap，就可以通过使用分段锁来提高并发度，从而避免大量的锁竞争。
* 协程 - 在单线程中实现多任务的调度，并在单线程里维持多个任务的切换。

### 死锁 <div id="dead-lock" />
当我们面对并发编程时可能遇到的竞争条件时，我们有时需要使用锁来对资源的访问进行控制，否则我们程序的执行结果就可能是错误的，花费了大量的算力最终得到的却是一个没有意义的结果。

锁使用简单，易于理解，但是同时也会给大家带来一定的困扰，其中一个就是死锁。一旦产生死锁，就会造成系统功能不可用，而且很难恢复。死锁发生通常意味着我们访问资源的顺序出现了问题。比如线程A访问资源1，2；线程B则尝试访问资源2，1；如果A获取到了控制资源一访问的互斥锁，同时B获取到了资源2的锁那么， 此时线程A，B都将无法再继续向下执行，此时我们就称作是发生了死锁。

#### 如何避免死锁 <div id="how-to-avoid-dead-lock" />
* 避免同一个线程获取多个锁。我们编程时很难全盘考虑，如果一个线程可以获取多个锁，那么一旦我们疏忽了，没有控制好资源访问的顺序，那么就有可能发生死锁。
* 避免一个线程在锁内占用多个资源。
* 使用带超时的锁。加锁时，我们可以给上锁的过程设置一个超时时间，这样如果真的有死锁的状态发生，超时时间结束之后，至少可以保证一个线程能够正常地失败，其持有的锁得到释放，而另一个线程就可以获取到这个锁并继续执行了。

### 资源限制 <div id="resource-limitation" />
#### 什么是资源限制 <div id="what-is-resource-limitation" />
任何一台计算机，其能够提供的资源是有限的，比如，带宽，磁盘IO，CPU，内存，各种类型的连接数等等。拿带宽来说，如果链路的带宽是2M每秒，启动十个线程进行下载，总体的下载速度不会变成20M每秒。因为运营商给我们保证的上行、下行速度是一定的。

#### 资源限制带来的问题 <div id="issues-caused-by-rl" />
我们尝试使用并发编程是因为我们尝试将代码中原本串行执行的部分编程并发执行，但是如果调整之后，由于资源限制问题，其任然是在串行执行，那么我们可能反而达不到原来的效果了。像我之前提到的一个CPU密集型的任务，当你增加线程数量时，只不过白白花费了CPU的算力做上下文切换罢了。

#### 如何解决资源限制问题 <div id="how-to-solve-rl" />
通常我们可以通过两种方式解决这个问题
* 第一种 - 增加更多的硬件，比如对于IO密集型的任务，我们可以在保持算力不变的情况扩充核心数量，比如之前是四核的，我们现在换成八核，十六核，这样我们就可以让更多的线程同时并行执行。对于CPU密集型的任务，我们可以在算力不变的情况下减少CPU的核心数，因为有一些线程池的实现会把CPU核心数作为线程池大小计算的依据，或许，减少了CPU核心数量，总体的线程数量反而变少了，那么浪费在线程上下文切换上的算力也反而变少了。
* 第二种 - 调整软件实现方式，我们有很多的池化技术，线程池，连接池，对象池等等，就是因为在资源创建和销毁的过程中也是很消耗资源的，包括内存以及CPU的计算时间，所以将这些资源缓存起来，使用特定的策略进行维护可能会是你获得意想不到的收益。

#### 在资源限制的基础上进行并发编程 <div id="programing-based-on-rl" />
当我们进行并发编程时，我们必须对自己的资源和自己将要处理的任务有一个清晰的认知。我处理的究竟是CPU密集型的任务还是IO密集型的任务。我的硬件资源里面，带宽，CPU，磁盘IO，内存大小，究竟哪一个才是我第一个遇到的瓶颈。这样我们才能对症下药，获得更好的性能。